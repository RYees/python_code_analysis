%
%
%import pandas as pd

from sqlalchemy import create_engine

from urllib.parse import quote
 
username = 'postgres'

password = 'nati@postgres'

hostname = 'localhost'

port = '5432'

database_name = 'TellCo'
 
escaped_password = quote(password, safe='')
 
engine = create_engine(f'postgresql://{username}:{escaped_password}@{hostname}:{port}/{database_name}')
 
with engine.connect() as connection:
  query = """
  SELECT *
  FROM xdr_data
  """
  df = pd.read_sql(query, connection)
 
df.head()

handset_counts = df['Handset Type'].value_counts()
 
top_10_handsets = handset_counts.head(10)
 
print(top_10_handsets)

manufacturer_counts = df['Handset Manufacturer'].value_counts()
 
top_3_manufacturers = manufacturer_counts.head(3)
 
print(top_3_manufacturers)
top_3_manufacturers = manufacturer_counts.head(3).index
 
for manufacturer in top_3_manufacturers:
  filtered_df = df[df['Handset Manufacturer'] == manufacturer]
  handset_counts = filtered_df['Handset Type'].value_counts()
  top_5_handsets = handset_counts.head(5)
  print(f"Top 5 handsets for {manufacturer}:")
  print(top_5_handsets)

aggregated_data = df.groupby('IMSI').agg({
  'Dur. (ms)': 'count',
  'Dur. (ms).1': 'sum',
  'Total DL (Bytes)': 'sum',
  'Total UL (Bytes)': 'sum',
  'Social Media DL (Bytes)': 'sum',
  'Social Media UL (Bytes)': 'sum',
  'Youtube DL (Bytes)': 'sum',
  'Youtube UL (Bytes)': 'sum',
  'Google DL (Bytes)': 'sum',
  'Google UL (Bytes)': 'sum',
  'Netflix DL (Bytes)': 'sum',
  'Netflix UL (Bytes)': 'sum',
  'Email DL (Bytes)': 'sum',
  'Email UL (Bytes)': 'sum',
  'Gaming DL (Bytes)': 'sum',
  'Gaming UL (Bytes)': 'sum',
  'Other DL (Bytes)': 'sum',
  'Other UL (Bytes)': 'sum'

})
 
aggregated_data['Social Media (Bytes)'] = aggregated_data['Social Media UL (Bytes)'] + aggregated_data['Social Media DL (Bytes)']

aggregated_data['Youtube (Bytes)'] = aggregated_data['Youtube UL (Bytes)'] + aggregated_data['Youtube DL (Bytes)']

aggregated_data['Google (Bytes)'] = aggregated_data['Google UL (Bytes)'] + aggregated_data['Google DL (Bytes)']

aggregated_data['Email (Bytes)'] = aggregated_data['Email UL (Bytes)'] + aggregated_data['Email DL (Bytes)']

aggregated_data['Netflix (Bytes)'] = aggregated_data['Netflix UL (Bytes)'] + aggregated_data['Netflix DL (Bytes)']

aggregated_data['Gaming (Bytes)'] = aggregated_data['Gaming UL (Bytes)'] + aggregated_data['Gaming DL (Bytes)']

aggregated_data['Other (Bytes)'] = aggregated_data['Other UL (Bytes)'] + aggregated_data['Other DL (Bytes)']
 
aggregated_data.drop(columns=['Other UL (Bytes)', 'Other DL (Bytes)', 'Gaming UL (Bytes)', 'Gaming DL (Bytes)', 'Netflix UL (Bytes)', 'Netflix DL (Bytes)', 'Email UL (Bytes)', 'Email DL (Bytes)', 'Social Media UL (Bytes)', 'Social Media DL (Bytes)', 'Youtube UL (Bytes)', 'Youtube DL (Bytes)', 'Google UL (Bytes)', 'Google DL (Bytes)'], inplace=True)
 
aggregated_data = aggregated_data.rename(columns={
  'Dur. (ms)': 'Number of xDR sessions',
  'Dur. (ms).1': 'Total Session duration (ms)'

})
 
aggregated_data
import pandas as pd

import numpy as np

import matplotlib

from sqlalchemy import create_engine

from urllib.parse import quote
 
import matplotlib.pyplot as plt

import seaborn as sns

from sklearn.decomposition import PCA

from sklearn.preprocessing import StandardScaler, MinMaxScaler

from sklearn.cluster import KMeans
def plot_hist(df:pd.DataFrame, column:str, color:str)->None:
  sns.displot(data=df, x=column, color=color, kde=True, height=7, aspect=2)
  plt.title(f'Distribution of {column}', size=20, fontweight='bold')
  plt.show()
 
def plot_count(df:pd.DataFrame, column:str) -> None:
  plt.figure(figsize=(12, 7))
  sns.countplot(data=df, x=column)
  plt.title(f'Distribution of {column}', size=20, fontweight='bold')
  plt.show()
 
def plot_bar(df:pd.DataFrame, x_col:str, y_col:str, title:str, xlabel:str, ylabel:str)->None:
  plt.figure(figsize=(12, 7))
  sns.barplot(data = df, x=x_col, y=y_col)
  plt.title(title, size=20)
  plt.xticks(rotation=75, fontsize=14)
  plt.yticks( fontsize=14)
  plt.xlabel(xlabel, fontsize=16)
  plt.ylabel(ylabel, fontsize=16)
  plt.show()
 
def plot_heatmap(df:pd.DataFrame, title:str, cbar=False)->None:
  plt.figure(figsize=(12, 7))
  sns.heatmap(df, annot=True, cmap='viridis', vmin=0, vmax=1, fmt='.2f', linewidths=.7, cbar=cbar )
  plt.title(title, size=18, fontweight='bold')
  plt.show()
 
def plot_box(df:pd.DataFrame, x_col:str, title:str) -> None:
  plt.figure(figsize=(12, 7))
  sns.boxplot(data = df, x=x_col)
  plt.title(title, size=20)
  plt.xticks(rotation=75, fontsize=14)
  plt.show()
 
def plot_box_multi(df:pd.DataFrame, x_col:str, y_col:str, title:str) -> None:
  plt.figure(figsize=(12, 7))
  sns.boxplot(data = df, x=x_col, y=y_col)
  plt.title(title, size=20)
  plt.xticks(rotation=75, fontsize=14)
  plt.yticks( fontsize=14)
  plt.show()
 
def plot_scatter(df: pd.DataFrame, x_col: str, y_col: str, title: str, hue: str, style: str) -> None:
  plt.figure(figsize=(12, 7))
  sns.scatterplot(data = df, x=x_col, y=y_col, hue=hue, style=style)
  plt.title(title, size=20)
  plt.xticks(fontsize=14)
  plt.yticks( fontsize=14)
  plt.show()
username = 'postgres'

password = 'nati@postgres'

hostname = 'localhost'

port = '5432'

database_name = 'TellCo'
 
escaped_password = quote(password, safe='')
 
engine = create_engine(f'postgresql://{username}:{escaped_password}@{hostname}:{port}/{database_name}')
 
with engine.connect() as connection:
  query = """
  SELECT *
  FROM xdr_data
  """
  df = pd.read_sql(query, connection)
 
df.head()
 
session_frequency = df.groupby('MSISDN/Number')['IMEI'].nunique()
 
engagement_metrics = df.groupby('MSISDN/Number').agg({
  'IMEI': 'nunique',   'Dur. (ms)': 'sum',   'Total UL (Bytes)': 'sum',   'Total DL (Bytes)': 'sum'  
})
 
engagement_metrics['Session Frequency'] = session_frequency

engagement_metrics['Total UL (GB)'] = engagement_metrics['Total UL (Bytes)'] / 1e9

engagement_metrics['Total DL (GB)'] = engagement_metrics['Total DL (Bytes)'] / 1e9
 
engagement_metrics['Total Data Volume (GB)'] = engagement_metrics['Total UL (GB)'] + engagement_metrics['Total DL (GB)']
 
engagement_metrics = engagement_metrics.drop(['Total DL (Bytes)', 'Total UL (Bytes)'], axis=1)
 
top_10_frequency = engagement_metrics.sort_values('IMEI', ascending=False).head(10)

top_10_duration = engagement_metrics.sort_values('Dur. (ms)', ascending=False).head(10)

top_10_traffic = engagement_metrics.sort_values('Total Data Volume (GB)', ascending=False).head(10)
 
print("Top 10 Customers by Sessions Frequency:")

print(top_10_frequency[['IMEI', 'Session Frequency']])
 
print("\nTop 10 Customers by Session Duration:")

print(top_10_duration[['IMEI', 'Dur. (ms)']])
 
print("\nTop 10 Customers by Sessions Total Traffic:")

print(top_10_traffic[['IMEI', 'Total Data Volume (GB)']])

kmeans = KMeans(n_clusters=3)

kmeans.fit(engagement_metrics)
 
cluster_labels = {0: 'High Engagement', 1: 'Medium Engagement', 2: 'Low Engagement'}
 
engagement_metrics['Cluster'] = kmeans.labels_

engagement_metrics['Cluster'] = engagement_metrics['Cluster'].map(cluster_labels)
 
grouped_metrics = engagement_metrics.groupby('Cluster')
 
cluster_stats = grouped_metrics.agg({
  'Session Frequency': ['min', 'max', 'mean', 'sum'],
  'Dur. (ms)': ['min', 'max', 'mean', 'sum'],
  'Total Data Volume (GB)': ['min', 'max', 'mean', 'sum']

})
 
cluster_stats.columns = ['Min Session Frequency', 'Max Session Frequency', 'Average Session Frequency', 'Total Session Frequency',
  'Min Duration', 'Max Duration', 'Average Duration', 'Total Duration',
  'Min Data Volume', 'Max Data Volume', 'Average Data Volume', 'Total Data Volume']
 
print("\nCluster Metrics:")

cluster_stats

scaler = StandardScaler()

normalized_metrics = scaler.fit_transform(engagement_metrics)
 
kmeans = KMeans(n_clusters=3)

kmeans.fit(normalized_metrics)
 
cluster_labels = {0: 'High Engagement', 1: 'Medium Engagement', 2: 'Low Engagement'}
 
engagement_metrics['Cluster'] = kmeans.labels_

engagement_metrics['Cluster'] = engagement_metrics['Cluster'].map(cluster_labels)
 
clustered_metrics = engagement_metrics[['Session Frequency', 'Dur. (ms)', 'Total Data Volume (GB)', 'Cluster']]
 
print("\nClustering Results:")

clustered_metrics.head(20)
 
application_columns = ['Social Media', 'Google', 'Email', 'Youtube', 'Netflix', 'Gaming', 'Other']
 
total_data = {}

for app in application_columns:
  total_data[app] = df[app + ' DL (Bytes)'].sum() + df[app + ' UL (Bytes)'].sum()
 
total_data_df = pd.DataFrame.from_dict(total_data, orient='index', columns=['Total Data Volume'])

total_data_df.index.name = 'Applications'
 
top_3_apps = total_data_df.nlargest(3, 'Total Data Volume')
 
plot_bar(df=top_3_apps,
  x_col= top_3_apps.index,
  y_col='Total Data Volume',
  title='Total Upload + Download Data Volume vs. Application',
  xlabel='Applications',
  ylabel='Total Data Volume')

plt.pie(top_3_apps['Total Data Volume'], labels=top_3_apps.index, autopct='%1.1f%%')

plt.title('Top 3 Most Used Applications')

plt.axis('equal')

plt.show()
import pandas as pd

import numpy as np

import matplotlib

from sqlalchemy import create_engine

from urllib.parse import quote
 
import matplotlib.pyplot as plt

import seaborn as sns

from sklearn.decomposition import PCA

from sklearn.preprocessing import StandardScaler, MinMaxScaler

from sklearn.cluster import KMeans

from sklearn.metrics import pairwise_distances_argmin_min
username = 'postgres'

password = 'nati@postgres'

hostname = 'localhost'

port = '5432'

database_name = 'TellCo'
 
escaped_password = quote(password, safe='')
 
engine = create_engine(f'postgresql://{username}:{escaped_password}@{hostname}:{port}/{database_name}')
 
with engine.connect() as connection:
  query = """
  SELECT *
  FROM xdr_data
  """
  df = pd.read_sql(query, connection)
 
df.head()
selected_fields = ['MSISDN/Number', 'TCP DL Retrans. Vol (Bytes)', 'Avg RTT DL (ms)', 'Avg Bearer TP DL (kbps)']

duplicates = df[df.duplicated(subset=selected_fields, keep=False)].copy()

duplicates['Count'] = duplicates.groupby(selected_fields)['MSISDN/Number'].transform('count')

duplicates.loc[:, ['MSISDN/Number', 'TCP DL Retrans. Vol (Bytes)', 'Avg RTT DL (ms)', 'Avg Bearer TP DL (kbps)', 'Count']]
df.columns
def detect_outliers(df):
  Q1 = df.quantile(0.25)
  Q3 = df.quantile(0.75)
  IQR = Q3 - Q1
  outliers = ((df < (Q1 - 1.5 * IQR)) | (df > (Q3 + 1.5 * IQR)))
  return outliers

for column in df.columns:
  data = df[column]
  if np.issubdtype(data.dtype, np.number):
  outliers = detect_outliers(data)
  column_mean = data.mean()
  df.loc[outliers, column] = column_mean
  df.loc[data.isnull(), column] = column_mean
  else:
  column_mode = data.mode().values[0]
  df.loc[data.isnull(), column] = column_mode

result_df = df.copy()
 
experience_metrics = result_df[['TCP DL Retrans. Vol (Bytes)', 'Avg RTT DL (ms)', 'Avg Bearer TP DL (kbps)']]
 
scaler = MinMaxScaler()

normalized_experience_metrics = pd.DataFrame(scaler.fit_transform(experience_metrics), columns=experience_metrics.columns)
 
kmeans = KMeans(n_clusters=3, random_state=42)

result_df['Experience Cluster'] = kmeans.fit_predict(normalized_experience_metrics)
 
worst_experience_cluster_label = np.argmax(kmeans.transform(normalized_experience_metrics), axis=1)

worst_experience_cluster_samples = normalized_experience_metrics.iloc[worst_experience_cluster_label == worst_experience_cluster_label.max()]
 
worst_experience_centroid = worst_experience_cluster_samples.mean()
 
result_df['Experience Score'] = pairwise_distances_argmin_min(normalized_experience_metrics, worst_experience_centroid.values.reshape(1, -1))[1]
 
print("User Data with Experience Cluster and Experience Score:")

result_df[['TCP DL Retrans. Vol (Bytes)', 'Avg RTT DL (ms)', 'Avg Bearer TP DL (kbps)', 'Experience Cluster', 'Experience Score']].head(20)

result_df_engagement = df.copy()
 
result_df_engagement = result_df_engagement.rename(columns={'Dur. (ms)': 'Session Duration (ms)'})
 
session_frequency = result_df_engagement.groupby('MSISDN/Number').size().reset_index(name='Session Frequency')
 
result_df_engagement = pd.merge(result_df_engagement, session_frequency, on='MSISDN/Number', how='left')
 
result_df_engagement['Total UL + DL (Bytes)'] = result_df_engagement['Total UL (Bytes)'] + result_df_engagement['Total DL (Bytes)']
 
engagement_metrics = result_df_engagement[['Session Duration (ms)', 'Total UL + DL (Bytes)', 'Session Frequency']]
 
scaler_engagement = MinMaxScaler()

normalized_engagement_metrics = pd.DataFrame(scaler_engagement.fit_transform(engagement_metrics), columns=engagement_metrics.columns)
 
kmeans_engagement = KMeans(n_clusters=3, random_state=42)

result_df_engagement['Engagement Cluster'] = kmeans_engagement.fit_predict(normalized_engagement_metrics)
 
least_engaged_cluster_label = np.argmin(kmeans_engagement.transform(normalized_engagement_metrics), axis=1)

least_engaged_cluster_samples = normalized_engagement_metrics.iloc[least_engaged_cluster_label == least_engaged_cluster_label.min()]
 
least_engaged_centroid = least_engaged_cluster_samples.mean()
 
result_df_engagement['Engagement Score'] = pairwise_distances_argmin_min(normalized_engagement_metrics, least_engaged_centroid.values.reshape(1, -1))[1]
 
print("User Data with Engagement Cluster and Engagement Score:")

result_df_engagement[['Session Duration (ms)', 'Total UL + DL (Bytes)', 'Session Frequency', 'Engagement Cluster', 'Engagement Score']].head(20)
result_df_combined = result_df.copy()
 
result_df_combined['Engagement Score'] = result_df_engagement['Engagement Score']
 
result_df_combined['Satisfaction Score'] = (result_df_combined['Experience Score'] + result_df_combined['Engagement Score']) / 2
 
top_satisfied_customers = result_df_combined.sort_values(by='Satisfaction Score', ascending=False).head(10)
 
print("Top 10 Satisfied Customers:")

top_satisfied_customers[['MSISDN/Number', 'Experience Score', 'Engagement Score', 'Satisfaction Score']]

engagement_score = result_df_combined[['Engagement Score']]
 
kmeans_engagement_score = KMeans(n_clusters=2, random_state=42)

result_df_combined['Engagement Cluster'] = kmeans_engagement_score.fit_predict(engagement_score)
 
print("User Data with Engagement Cluster (k=2):")

result_df_combined[['MSISDN/Number', 'Engagement Score', 'Engagement Cluster']].head(20)

experience_score = result_df_combined[['Experience Score']]
 
kmeans_experience_score = KMeans(n_clusters=2, random_state=42)

result_df_combined['Experience Cluster'] = kmeans_experience_score.fit_predict(experience_score)
 
print("User Data with Experience Cluster (k=2):")

result_df_combined[['MSISDN/Number', 'Experience Score', 'Experience Cluster']].head(20)

satisfaction_result_df = result_df_combined[['MSISDN/Number', 'Experience Score', 'Engagement Score', 'Satisfaction Score']].copy()
 
satisfaction_result_df.to_sql('satisfaction_result_df', con=engine, if_exists='replace', index=False)

with engine.connect() as connection:
  query = """
  SELECT *
  FROM satisfaction_result_df
  """
  satisfaction_result_query_df = pd.read_sql(query, connection)
 
satisfaction_result_query_df.head()
import streamlit as st
import os, sys, pandas

rpath = os.path.abspath('..')
if rpath not in sys.path:
  sys.path.insert(0, rpath)

from Dashboard import general_analysis
from Dashboard import overview_analysis
from Dashboard import engagment_analysis
from Dashboard import experience_analysis
from Dashboard import satisfaction_analysis

st.set_page_config(page_title="TellCo Data Analysis")

st.title("TellCo Data Analysis")

menu_options = [
  "General Analysis",
  "User Overview Analysis",
  "User Engagement Analysis",
  "User Experience Analysis",
  "User Satisfaction Analysis",
]

st.sidebar.markdown("<h1 style='text-align: center;'>Navigation</h1>", unsafe_allow_html=True)

selected_page = st.sidebar.radio("", menu_options, index=0)

if selected_page == "General Analysis":
  general_analysis.show()

elif selected_page == "User Overview Analysis":
  overview_analysis.show()

elif selected_page == "User Engagement Analysis":
  engagment_analysis.show()

elif selected_page == "User Experience Analysis":
  experience_analysis.show()

elif selected_page == "User Satisfaction Analysis":
  satisfaction_analysis.show()
import streamlit as st
import pandas as pd
import os, sys
from sqlalchemy import create_engine
from urllib.parse import quote
import matplotlib.pyplot as plt
import seaborn as sns

rpath = os.path.abspath('..')
if rpath not in sys.path:
  sys.path.insert(0, rpath)

username = 'postgres'
password = 'nati@postgres'
hostname = 'localhost'
port = '5432'
database_name = 'TellCo'

escaped_password = quote(password, safe='')

engine = create_engine(f'postgresql://{username}:{escaped_password}@{hostname}:{port}/{database_name}')

def show():
  st.header("User Engagement Analysis Page")
  engagement_option = st.selectbox(
  'Select an analysis:',
  [
  'Top 3 Most Used Applications',
  'Top 10 Users by Engagment Score',
  'Engagement Score Changes for the Last 20,000 xDR Sessions']
  )
  if engagement_option == 'Top 3 Most Used Applications':
  show_top_3_applications()
  elif engagement_option == 'Top 10 Users by Engagment Score':
  show_top_10_users_by_engagement_score()
  elif engagement_option == 'Engagement Score Changes for the Last 20,000 xDR Sessions':
  show_engagement_score_changes()
 
def show_top_3_applications():
  query_xdr = """
  SELECT *
  FROM xdr_data
  """
  df = pd.read_sql(query_xdr, engine)
  application_columns = ['Social Media', 'Google', 'Email', 'Youtube', 'Netflix', 'Gaming', 'Other']
  total_data = {}
  for app in application_columns:
  total_data[app] = df[app + ' DL (Bytes)'].sum() + df[app + ' UL (Bytes)'].sum()
  total_data_df = pd.DataFrame.from_dict(total_data, orient='index', columns=['Total Data Volume'])
  total_data_df.index.name = 'Applications'
  top_3_apps = total_data_df.nlargest(3, 'Total Data Volume')
  fig, ax = plt.subplots()
  sns.barplot(x=top_3_apps.index, y='Total Data Volume', data=top_3_apps, ax=ax)
  ax.set_title('Total Upload + Download Data Volume vs. Application')
  ax.set_xlabel('Applications')
  ax.set_ylabel('Total Data Volume')
  st.pyplot(fig)

def show_top_10_users_by_engagement_score():
  """
  This function displays the top 10 users based on their engagement scores.
  """
  query = """
  SELECT *
  FROM satisfaction_result_df;
  """
  data = pd.read_sql(query, engine)
  data_sorted = data.sort_values(by='Engagement Score', ascending=False)
  top_10_users = data_sorted.head(10)
  st.subheader("Top 10 Users by Engagement Score")
  st.table(top_10_users[['MSISDN/Number', 'Engagement Score']])
 
def show_engagement_score_changes():
  query = """
  SELECT srdf."MSISDN/Number", srdf."Engagement Score", xd."Start"
  FROM satisfaction_result_df srdf
  LEFT JOIN xdr_data xd ON srdf."MSISDN/Number" = xd."MSISDN/Number"
  """
  df_combined = pd.read_sql(query, engine)
  df_filtered = df_combined.dropna(subset=['Engagement Score', 'Start'])
  df_sorted = df_filtered.sort_values(by='Start', ascending=True)
  df_recent = df_sorted.tail(20000)
  df_recent['Start'] = pd.to_datetime(df_recent['Start'])
  df_recent_sorted = df_recent.sort_values(by='Start')
  window_size = 1000   df_recent_sorted['Engagement Score MA'] = df_recent_sorted['Engagement Score'].rolling(window=window_size).mean()
  fig, ax = plt.subplots(figsize=(12, 6))
  sns.lineplot(data=df_recent_sorted, x=df_recent_sorted.index, y='Engagement Score', ax=ax, label='Engagement Score')
  sns.lineplot(data=df_recent_sorted, x=df_recent_sorted.index, y='Engagement Score MA', ax=ax, label='Engagement Score MA', color='red')
  ax.set_title('Time Series Analysis of Engagement Scores (Most Recent 20,000 Sessions) with Moving Average')
  ax.set_xlabel('Start')
  ax.set_ylabel('Engagement Score')
  ax.tick_params(rotation=45)
  ax.legend()
  st.pyplot(fig)
import streamlit as st
import pandas as pd
import os, sys
from sqlalchemy import create_engine
from urllib.parse import quote
import matplotlib.pyplot as plt
import seaborn as sns

rpath = os.path.abspath('..')
if rpath not in sys.path:
  sys.path.insert(0, rpath)

username = 'postgres'
password = 'nati@postgres'
hostname = 'localhost'
port = '5432'
database_name = 'TellCo'

escaped_password = quote(password, safe='')

engine = create_engine(f'postgresql://{username}:{escaped_password}@{hostname}:{port}/{database_name}')
 
def show():
  st.header("General User Score Analysis Page")
  main_option = st.selectbox(
  'Select an analysis:',
  ['Distribution of user analysis scores', 'Distribution of user analysis scores with Handset groups', 'Time series analysis of user analysis scores']
  )
  if main_option == 'Distribution of user analysis scores':
  show_distribution_of_scores()
  elif main_option == 'Distribution of user analysis scores with Handset groups':
  show_distribution_with_handset_groups()
  elif main_option == 'Time series analysis of user analysis scores':
  show_time_series_analysis()
 
def show_distribution_of_scores():
  st.subheader("Distribution of User Analysis Scores")
  query = """
  SELECT "Experience Score", "Engagement Score", "Satisfaction Score"
  FROM satisfaction_result_df
  """
  df_scores = pd.read_sql(query, engine)
  top_25_exp = df_scores["Experience Score"].quantile(0.75)
  top_50_exp = df_scores["Experience Score"].quantile(0.5)
  top_75_exp = df_scores["Experience Score"].quantile(0.25)
  all_users_exp = df_scores["Experience Score"].mean()
  top_25_eng = df_scores["Engagement Score"].quantile(0.75)
  top_50_eng = df_scores["Engagement Score"].quantile(0.5)
  top_75_eng = df_scores["Engagement Score"].quantile(0.25)
  all_users_eng = df_scores["Engagement Score"].mean()
  top_25_sat = df_scores["Satisfaction Score"].quantile(0.75)
  top_50_sat = df_scores["Satisfaction Score"].quantile(0.5)
  top_75_sat = df_scores["Satisfaction Score"].quantile(0.25)
  all_users_sat = df_scores["Satisfaction Score"].mean()
  result_df = pd.DataFrame({
  'Experience Score': [top_25_exp, top_50_exp, top_75_exp, all_users_exp],
  'Engagement Score': [top_25_eng, top_50_eng, top_75_eng, all_users_eng],
  'Satisfaction Score': [top_25_sat, top_50_sat, top_75_sat, all_users_sat],
  }, index=['Top 25%', 'Top 50%', 'Top 75%', 'All Users'])
  color_scale = sns.light_palette("seagreen", as_cmap=True)
  st.table(result_df.style.background_gradient(cmap=color_scale, axis=None))
 
def show_distribution_with_handset_groups():
  query = """
  SELECT srdf."MSISDN/Number", srdf."Experience Score", srdf."Engagement Score", srdf."Satisfaction Score", xd."Handset Manufacturer"
  FROM satisfaction_result_df srdf
  LEFT JOIN xdr_data xd ON srdf."MSISDN/Number" = xd."MSISDN/Number"
  """
  df_combined = pd.read_sql(query, engine)
  valid_handset_values = ['Apple', 'Samsung', 'Huawei']
  df_filtered = df_combined[df_combined['Handset Manufacturer'].isin(valid_handset_values)]
  avg_scores = df_filtered.groupby('Handset Manufacturer').agg({
  'Experience Score': 'mean',
  'Engagement Score': 'mean',
  'Satisfaction Score': 'mean'
  }).transpose()
  color_scale = sns.light_palette("seagreen", as_cmap=True)
  st.subheader("Distribution of User Analysis Scores with Handset Groups")
  st.table(avg_scores.style.background_gradient(cmap=color_scale, axis=None))
 
def show_time_series_analysis():
  sub_option = st.selectbox(
  'Select a sub-analysis:',
  ['Time series analysis of experiance scores', 'Time series analysis of engagment scores', 'Time series analysis of satisfaction scores']
  )
  if sub_option == 'Time series analysis of experiance scores':
  show_time_series_experience_scores()
  elif sub_option == 'Time series analysis of engagment scores':
  show_time_series_engagement_scores()
  elif sub_option == 'Time series analysis of satisfaction scores':
  show_time_series_satisfaction_scores()

def show_time_series_experience_scores():
  query = """
  SELECT srdf."MSISDN/Number", srdf."Experience Score", xd."Start"
  FROM satisfaction_result_df srdf
  LEFT JOIN xdr_data xd ON srdf."MSISDN/Number" = xd."MSISDN/Number"
  """
  df_combined = pd.read_sql(query, engine)
  df_filtered = df_combined.dropna(subset=['Experience Score', 'Start'])
  df_sorted = df_filtered.sort_values(by='Start', ascending=True)
  df_recent = df_sorted.tail(20000)
  df_recent['Start'] = pd.to_datetime(df_recent['Start'])
  df_recent_sorted = df_recent.sort_values(by='Start')
  window_size = 1000   df_recent_sorted['Experience Score MA'] = df_recent_sorted['Experience Score'].rolling(window=window_size).mean()
  fig, ax = plt.subplots(figsize=(12, 6))
  sns.lineplot(data=df_recent_sorted, x=df_recent_sorted.index, y='Experience Score', ax=ax, label='Experience Score')
  sns.lineplot(data=df_recent_sorted, x=df_recent_sorted.index, y='Experience Score MA', ax=ax, label='Experience Score MA', color='red')
  ax.set_title('Time Series Analysis of Experience Scores (Most Recent 20,000 Sessions) with Moving Average')
  ax.set_xlabel('Start')
  ax.set_ylabel('Experience Score')
  ax.tick_params(rotation=45)
  ax.legend()
  st.pyplot(fig)
 
def show_time_series_engagement_scores():
  query = """
  SELECT srdf."MSISDN/Number", srdf."Engagement Score", xd."Start"
  FROM satisfaction_result_df srdf
  LEFT JOIN xdr_data xd ON srdf."MSISDN/Number" = xd."MSISDN/Number"
  """
  df_combined = pd.read_sql(query, engine)
  df_filtered = df_combined.dropna(subset=['Engagement Score', 'Start'])
  df_sorted = df_filtered.sort_values(by='Start', ascending=True)
  df_recent = df_sorted.tail(20000)
  df_recent['Start'] = pd.to_datetime(df_recent['Start'])
  df_recent_sorted = df_recent.sort_values(by='Start')
  window_size = 1000   df_recent_sorted['Engagement Score MA'] = df_recent_sorted['Engagement Score'].rolling(window=window_size).mean()
  fig, ax = plt.subplots(figsize=(12, 6))
  sns.lineplot(data=df_recent_sorted, x=df_recent_sorted.index, y='Engagement Score', ax=ax, label='Engagement Score')
  sns.lineplot(data=df_recent_sorted, x=df_recent_sorted.index, y='Engagement Score MA', ax=ax, label='Engagement Score MA', color='red')
  ax.set_title('Time Series Analysis of Engagement Scores (Most Recent 20,000 Sessions) with Moving Average')
  ax.set_xlabel('Start')
  ax.set_ylabel('Engagement Score')
  ax.tick_params(rotation=45)
  ax.legend()
  st.pyplot(fig)

def show_time_series_satisfaction_scores():
  query = """
  SELECT srdf."MSISDN/Number", srdf."Satisfaction Score", xd."Start"
  FROM satisfaction_result_df srdf
  LEFT JOIN xdr_data xd ON srdf."MSISDN/Number" = xd."MSISDN/Number"
  """
  df_combined = pd.read_sql(query, engine)
  df_filtered = df_combined.dropna(subset=['Satisfaction Score', 'Start'])
  df_sorted = df_filtered.sort_values(by='Start', ascending=True)
  df_recent = df_sorted.tail(20000)
  df_recent['Start'] = pd.to_datetime(df_recent['Start'])
  df_recent_sorted = df_recent.sort_values(by='Start')
  window_size = 1000   df_recent_sorted['Satisfaction Score MA'] = df_recent_sorted['Satisfaction Score'].rolling(window=window_size).mean()
  fig, ax = plt.subplots(figsize=(12, 6))
  sns.lineplot(data=df_recent_sorted, x=df_recent_sorted.index, y='Satisfaction Score', ax=ax, label='Satisfaction Score')
  sns.lineplot(data=df_recent_sorted, x=df_recent_sorted.index, y='Satisfaction Score MA', ax=ax, label='Satisfaction Score MA', color='red')
  ax.set_title('Time Series Analysis of Satisfaction Scores (Most Recent 20,000 Sessions) with Moving Average')
  ax.set_xlabel('Start')
  ax.set_ylabel('Satisfaction Score')
  ax.tick_params(rotation=45)
  ax.legend()
  st.pyplot(fig)

if __name__ == '__main__':
  show()
import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sqlalchemy import create_engine
from urllib.parse import quote

username = 'postgres'
password = 'nati@postgres'
hostname = 'localhost'
port = '5432'
database_name = 'TellCo'

escaped_password = quote(password, safe='')

engine = create_engine(f'postgresql://{username}:{escaped_password}@{hostname}:{port}/{database_name}')

def show():
  st.header("User Overview Analysis Page")
  analysis_option = st.selectbox(
  'Select an analysis:',
  ['Top 5 Handset Manufacturers', 'Distribution of Total DL', 'Distribution of Total UL', 'Total UL + DL vs. Application', 'Correlation Analysis']
  )
  if analysis_option == 'Top 5 Handset Manufacturers':
  show_top_manufacturers()
  elif analysis_option == 'Distribution of Total DL':
  show_distribution_total_dl()
  elif analysis_option == 'Distribution of Total UL':
  show_distribution_total_ul()
  elif analysis_option == 'Total UL + DL vs. Application':
  show_total_vs_application()
  elif analysis_option == 'Correlation Analysis':
  show_correlation_analysis()

def show_top_manufacturers():
  st.subheader("Top 5 Handset Manufacturers")
  query_top_manufacturers = """
  SELECT "Handset Manufacturer", COUNT(*) AS "Count"
  FROM xdr_data
  GROUP BY "Handset Manufacturer"
  ORDER BY "Count" DESC
  LIMIT 5
  """
  df_top_manufacturers = pd.read_sql(query_top_manufacturers, engine)
  st.table(df_top_manufacturers)

def show_distribution_total_dl():
  st.subheader("Distribution of Total DL (Bar Plot)")
  query_total_dl = """
  SELECT "MSISDN/Number", "Total DL (Bytes)"
  FROM xdr_data
  """
  df_total_dl = pd.read_sql(query_total_dl, engine)
  fig, ax = plt.subplots()
  sns.histplot(data=df_total_dl, x='Total DL (Bytes)', bins=30, kde=True)
  ax.set_xlabel("Total DL (Bytes)")
  ax.set_ylabel("Count")
  ax.set_title("Distribution of Total DL")
  st.pyplot(fig)

def show_distribution_total_ul():
  st.subheader("Distribution of Total UL (Bar Plot)")
  query_total_ul = """
  SELECT "MSISDN/Number", "Total UL (Bytes)"
  FROM xdr_data
  """
  df_total_ul = pd.read_sql(query_total_ul, engine)
  fig, ax = plt.subplots()
  sns.histplot(data=df_total_ul, x='Total UL (Bytes)', bins=30, kde=True)
  ax.set_xlabel("Total UL (Bytes)")
  ax.set_ylabel("Count")
  ax.set_title("Distribution of Total UL")
  st.pyplot(fig)

def show_total_vs_application():
  st.subheader("Total UL + DL vs. Application")
  query_total_vs_application = """
  SELECT "MSISDN/Number", "Social Media DL (Bytes)", "Google DL (Bytes)", "Email DL (Bytes)", "Youtube DL (Bytes)",
  "Netflix DL (Bytes)", "Gaming DL (Bytes)", "Other DL (Bytes)",
  "Social Media UL (Bytes)", "Google UL (Bytes)", "Email UL (Bytes)", "Youtube UL (Bytes)",
  "Netflix UL (Bytes)", "Gaming UL (Bytes)", "Other UL (Bytes)"
  FROM xdr_data
  """
  df = pd.read_sql(query_total_vs_application, engine)
  application_columns = ['Social Media', 'Google', 'Email', 'Youtube', 'Netflix', 'Gaming', 'Other']
  total_data = {}
  for app in application_columns:
  total_data[app] = df[app + ' DL (Bytes)'].sum() + df[app + ' UL (Bytes)'].sum()
  total_data_df = pd.DataFrame.from_dict(total_data, orient='index', columns=['Total Data Volume'])
  total_data_df.index.name = 'Applications'
  fig, ax = plt.subplots()
  sns.barplot(x=total_data_df.index, y='Total Data Volume', data=total_data_df)
  ax.set_xlabel("Applications")
  ax.set_ylabel("Total Data Volume")
  ax.set_title("Total Upload + Download Data Volume vs. Application")
  ax.tick_params(rotation=45)
  st.pyplot(fig)

def show_correlation_analysis():
  st.subheader("Correlation Analysis")
  query_correlation = """
  SELECT "Social Media DL (Bytes)", "Social Media UL (Bytes)",
  "Youtube DL (Bytes)", "Youtube UL (Bytes)",
  "Netflix DL (Bytes)", "Netflix UL (Bytes)",
  "Google DL (Bytes)", "Google UL (Bytes)",
  "Email DL (Bytes)", "Email UL (Bytes)",
  "Gaming DL (Bytes)", "Gaming UL (Bytes)",
  "Other DL (Bytes)", "Other UL (Bytes)"
  FROM xdr_data
  """
  df = pd.read_sql(query_correlation, engine)
  total_data_volume = pd.DataFrame()
  total_data_volume['Social Media Total'] = df['Social Media DL (Bytes)'] + df['Social Media UL (Bytes)']
  total_data_volume['Youtube Total'] = df['Youtube DL (Bytes)'] + df['Youtube UL (Bytes)']
  total_data_volume['Netflix Total'] = df['Netflix DL (Bytes)'] + df['Netflix UL (Bytes)']
  total_data_volume['Google Total'] = df['Google DL (Bytes)'] + df['Google UL (Bytes)']
  total_data_volume['Email Total'] = df['Email DL (Bytes)'] + df['Email UL (Bytes)']
  total_data_volume['Gaming Total'] = df['Gaming DL (Bytes)'] + df['Gaming UL (Bytes)']
  total_data_volume['Other Total'] = df['Other DL (Bytes)'] + df['Other UL (Bytes)']
  correlation_matrix = total_data_volume.corr()
  color_scale = sns.light_palette("seagreen", as_cmap=True)
  st.table(correlation_matrix.style.background_gradient(cmap=color_scale, axis=None))
import streamlit as st
import pandas as pd
import os, sys
from sqlalchemy import create_engine
from urllib.parse import quote
import matplotlib.pyplot as plt
import seaborn as sns

rpath = os.path.abspath('..')
if rpath not in sys.path:
  sys.path.insert(0, rpath)

username = 'postgres'
password = 'nati@postgres'
hostname = 'localhost'
port = '5432'
database_name = 'TellCo'

escaped_password = quote(password, safe='')

engine = create_engine(f'postgresql://{username}:{escaped_password}@{hostname}:{port}/{database_name}')
 
def show():
  st.header("User Satisfaction Page")
  main_option = st.selectbox(
  'Select an analysis:',
  ['Top 10 Users by Satisfaction Score', 'Satisfaction Score Changes for the Last 20,000 xDR Sessions']
  )
  if main_option == 'Top 10 Users by Satisfaction Score':
  top_10_users_by_satisfaction_score()
  elif main_option == 'Satisfaction Score Changes for the Last 20,000 xDR Sessions':
  show_time_series_satisfaction_scores()
 
def top_10_users_by_satisfaction_score():
  """
  This function displays the top 10 users based on their Satisfaction scores.
  """
  query = """
  SELECT *
  FROM satisfaction_result_df;
  """
  data = pd.read_sql(query, engine)
  data_sorted = data.sort_values(by='Satisfaction Score', ascending=False)
  top_10_users = data_sorted.head(10)
  st.subheader("Top 10 Users by Satisfaction Score")
  st.table(top_10_users[['MSISDN/Number', 'Satisfaction Score']])

def show_time_series_satisfaction_scores():
  query = """
  SELECT srdf."MSISDN/Number", srdf."Satisfaction Score", xd."Start"
  FROM satisfaction_result_df srdf
  LEFT JOIN xdr_data xd ON srdf."MSISDN/Number" = xd."MSISDN/Number"
  """
  df_combined = pd.read_sql(query, engine)
  df_filtered = df_combined.dropna(subset=['Satisfaction Score', 'Start'])
  df_sorted = df_filtered.sort_values(by='Start', ascending=True)
  df_recent = df_sorted.tail(20000)
  df_recent['Start'] = pd.to_datetime(df_recent['Start'])
  df_recent_sorted = df_recent.sort_values(by='Start')
  window_size = 1000   df_recent_sorted['Satisfaction Score MA'] = df_recent_sorted['Satisfaction Score'].rolling(window=window_size).mean()
  fig, ax = plt.subplots(figsize=(12, 6))
  sns.lineplot(data=df_recent_sorted, x=df_recent_sorted.index, y='Satisfaction Score', ax=ax, label='Satisfaction Score')
  sns.lineplot(data=df_recent_sorted, x=df_recent_sorted.index, y='Satisfaction Score MA', ax=ax, label='Satisfaction Score MA', color='red')
  ax.set_title('Time Series Analysis of Satisfaction Scores (Most Recent 20,000 Sessions) with Moving Average')
  ax.set_xlabel('Start')
  ax.set_ylabel('Satisfaction Score')
  ax.tick_params(rotation=45)
  ax.legend()
  st.pyplot(fig)