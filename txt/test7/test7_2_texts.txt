%import sys, os, json, re, zipfile, csv

import pandas as pd

import emoji

class Util():
  def __init__(self) -> None:
  self.emoji_pattern = re.compile(r"[\U0001F000-\U0001F9FF\U0001FA00-\U0001FFFF\U00020000-\U0002FFFF\U00030000-\U0003FFFF]+", flags=re.UNICODE)
  self.symbols = re.compile("["
  "\""
  "\“"
  "\""
  "\'"
  "\-"
  "\*"
  "\•"
  "\ℹ"
  "\﻿"
  "\_"
  "]+")
  self.url_pattern = r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+'
  self.mention_pattern = r'@(\w+)'
  def read_file(self, file_path: str) -> dict:
  with open(file_path, 'r') as file:
  data = json.load(file)
  return data
  def write_file(self, file_path: str, data: dict) -> None:
  with open(file_path, 'w') as file:
  json.dump(data, file, indent=2)
  def parse_text(self, text: any) -> str:
  if isinstance(text, str):
  return text
  elif isinstance(text, list):
  contents = []
  for item in text:
  if isinstance(item, str):
  contents.append(item)
  elif isinstance(item, dict):
  contents.append(item['text'])
  return "".join(contents)
  else:
  return ""
  def parse_messages(self, messages: list) -> dict:
  parsed_messages = {
  'id': [],
  'text': [],
  'date': []
  }
  for message in messages:
  if message['type'] != 'message' or len(message['text']) == 0:
  continue
  parsed_messages['id'].append(message['id'])
  message_content = self.parse_text(message['text'])
  parsed_messages['text'].append(message_content)
  parsed_messages['date'].append(message['date'])
  return parsed_messages
  def extract_hashtags(self, text: str) -> list:
  return [word for word in text.split() if word.startswith('
  def extract_emojis(self, text):
  return ''.join(self.emoji_pattern.findall(text))
  def remove_emojis(self, text):
  return self.emoji_pattern.sub('', text)
  def extract_symbols(self, text):
  return ''.join(self.symbols.findall(text))
  def remove_symbols(self, text):
  return self.symbols.sub(' ', text)
  def extract_urls(self, text):
  return re.findall(self.url_pattern, text)
  def extract_mentions(self, text):
  return re.findall(self.mention_pattern, text)
  def extract_fields(self, message):
  """
  Extracts relevant fields from the message.
  Returns a tuple containing (channel_id, text, date, labels).
  """
  text = ' '.join(item['text'] for item in message['text_entities'] if item['type'] in 'plain')
  date = message['date']
  labels = "LABEL"   return text, date, labels
  def process_json_file(self, json_file, csv_writer):
  """
  Processes a JSON file, extracts relevant fields, and writes to CSV.
  """
  data = json.load(json_file)
  channel_id = data['id']
  for message in data['messages']:
  text, date, labels = self.extract_fields(message)
  csv_writer.writerow([channel_id, text, date, labels])
  def process_zip(self, zip_file_path, output_csv_path):
  """
  Processes a zip file, extracts data from JSON files, and writes to a CSV file.
  """
  with zipfile.ZipFile(zip_file_path, 'r') as zip_file:
  with open(output_csv_path, 'w', newline='', encoding='utf-8') as csv_file:
  csv_writer = csv.writer(csv_file)
  csv_writer.writerow(['id', 'text', 'date', 'label'])
  for file_info in zip_file.infolist():
  with zip_file.open(file_info.filename) as json_file:
  print(json_file)
  self.process_json_file(json_file, csv_writer)
  def process_zip_files(self, zip_file_path, output_directory):
  with zipfile.ZipFile(zip_file_path, 'r') as zip_file:
  for file_info in zip_file.infolist():
  with zip_file.open(file_info.filename) as json_file:
  data = json.load(json_file)
  parsed_data = self.parse_json_data(data)
  df = pd.DataFrame(parsed_data)
  output_file_name = os.path.splitext(os.path.basename(file_info.filename))[0]
  output_csv_path = os.path.join(output_directory, f"{output_file_name}_parsed.csv")
  df.to_csv(output_csv_path, index=False)
  def parse_json_data(self, data):
  parsed_data = {
  'id': [],
  'text': [],
  'date': [],
  'label': []
  }
  for message in data['messages']:
  text, date, labels = self.extract_fields(message)
  parsed_data['id'].append(data['id'])
  parsed_data['text'].append(text)
  parsed_data['date'].append(date)
  parsed_data['label'].append(labels)
  return parsed_data
  def file_reader(self, path: str, ) -> str:
  fname = os.path.join(path)
  with open(fname, 'r') as f:
  system_message = f.read()
  return system_message

util = Util()
 
zip_file_path = "../data/raw/raw.zip"

output_csv_path = "../data/parsed/parsed.csv"
 
util.process_zip(zip_file_path, output_csv_path)

print("Parsing completed. Output saved to", output_csv_path)
 
parsed_csv_path = "../data/parsed/parsed.csv"

output_cleaned_csv_path = "../data/parsed/cleaned_parsed.csv"
 
df = pd.read_csv(parsed_csv_path)

df = df.dropna()

df.head()

df['text'] = df['text'].replace('\n', ' ', regex=True)

df.head()

df['text'] = df['text'].str.replace(r'\
df.head()
 
df['text'] = df['text'].apply(util.remove_emojis)

df.head()

df['text'] = df['text'].apply(util.remove_symbols)

df.head()

df['text'] = df['text'].str.replace(util.url_pattern, '', regex=True).str.strip()

df.head()
df['text'] = df['text'].str.replace(util.mention_pattern, '', regex=True).str.strip()

df.head()

df['text'] = df['text'].str.replace('\s+', ' ', regex=True).str.strip()

df['text'] = df['text'].replace(r'!+', '!', regex=True)

df['text'] = df['text'].replace(r'\.+', '', regex=True)

df.head()
 
letters = [
  [['ሐ', 'ሑ', 'ሒ', 'ሓ', 'ሔ', 'ሖ'], ['ሀ', 'ሁ', 'ሂ', 'ሃ', 'ሄ', 'ህ', 'ሆ']],
  [['ኀ', 'ኁ', 'ኂ', 'ኃ', 'ኄ', 'ኅ', 'ኆ'], ['ሀ', 'ሁ', 'ሂ', 'ሃ', 'ሄ', 'ህ', 'ሆ']],
  [['ሠ', 'ሡ', 'ሢ', 'ሣ', 'ሤ', 'ሦ', 'ሦ', 'ሧ'], ['ሰ', 'ሱ', 'ሲ', 'ሳ', 'ሴ', 'ስ', 'ሶ', 'ሷ']],
  [['ዐ', 'ዑ', 'ዒ', 'ዓ', 'ዔ', 'ዕ', 'ዖ'], ['አ', 'ኡ', 'ኢ', 'ኣ', 'ኤ', 'እ', 'ኦ']],
  [['ጸ', 'ጹ', 'ጺ', 'ጻ', 'ጼ', 'ጽ', 'ጾ'], ['ፀ', 'ፁ', 'ፂ', 'ፃ', 'ፄ', 'ፅ', 'ፆ']]

]
 
for letter in letters:
  for i in range(len(letter[0])):
  df['text'] = df['text'].str.replace(letter[0][i], letter[1][i])
 
df.head()  
df['text'] = df['text'].str.replace(r'[A-Za-z]+', '', regex=True)

df.head()

cleaned_output_path = "../data/parsed/cleaned_parsed_data.csv"

df.to_csv(cleaned_output_path, index=False)

output_text_path = "../data/cleaned/cleaned.txt"

df['text'] = df['text'].apply(util.remove_emojis)

df['text'].to_csv(output_text_path, index=False, header=False, sep='\t')
zip_file_path = "../data/raw/raw.zip"

output_directory = "../data/parsed/"

util.process_zip_files(zip_file_path, output_directory)
import os

import pandas as pd
 
parsed_files_directory = "../data/parsed/"

cleaned_files_directory = "../data/cleaned/"
 
for filename in os.listdir(parsed_files_directory):
  if filename.endswith("_parsed.csv"):
  filepath = os.path.join(parsed_files_directory, filename)
  df = pd.read_csv(filepath)
  df = df.dropna()
  df['text'] = df['text'].replace('\n', ' ', regex=True)
  df['text'] = df['text'].str.replace(r'\
  df['text'] = df['text'].apply(util.remove_emojis)
  df['text'] = df['text'].apply(util.remove_symbols)
  df['text'] = df['text'].str.replace(util.url_pattern, '', regex=True).str.strip()
  df['text'] = df['text'].str.replace(util.mention_pattern, '', regex=True).str.strip()
  df['text'] = df['text'].str.replace('\s+', ' ', regex=True).str.strip()
  df['text'] = df['text'].replace(r'!+', '!', regex=True)
  df['text'] = df['text'].replace(r'\.+', '', regex=True)
  letters = [
  [['ሐ', 'ሑ', 'ሒ', 'ሓ', 'ሔ', 'ሖ'], ['ሀ', 'ሁ', 'ሂ', 'ሃ', 'ሄ', 'ህ', 'ሆ']],
  [['ኀ', 'ኁ', 'ኂ', 'ኃ', 'ኄ', 'ኅ', 'ኆ'], ['ሀ', 'ሁ', 'ሂ', 'ሃ', 'ሄ', 'ህ', 'ሆ']],
  [['ሠ', 'ሡ', 'ሢ', 'ሣ', 'ሤ', 'ሦ', 'ሦ', 'ሧ'], ['ሰ', 'ሱ', 'ሲ', 'ሳ', 'ሴ', 'ስ', 'ሶ', 'ሷ']],
  [['ዐ', 'ዑ', 'ዒ', 'ዓ', 'ዔ', 'ዕ', 'ዖ'], ['አ', 'ኡ', 'ኢ', 'ኣ', 'ኤ', 'እ', 'ኦ']],
  [['ጸ', 'ጹ', 'ጺ', 'ጻ', 'ጼ', 'ጽ', 'ጾ'], ['ፀ', 'ፁ', 'ፂ', 'ፃ', 'ፄ', 'ፅ', 'ፆ']]
  ]
  for letter in letters:
  for i in range(len(letter[0])):
  df['text'] = df['text'].str.replace(letter[0][i], letter[1][i])
  df['text'] = df['text'].str.replace(r'[A-Za-z]+', '', regex=True)
  df.to_csv(filepath, index=False)
  cleaned_text_path = os.path.join(cleaned_files_directory, f"{os.path.splitext(filename)[0]}.txt")
  df['text'].to_csv(cleaned_text_path, index=False, header=False)
import os
import pandas as pd
from utils import Util

def clean(filepath):
  df = pd.read_csv(filepath)
  df = df.dropna()
  df['text'] = df['text'].replace('\n', ' ', regex=True)
  df['text'] = df['text'].str.replace(r'\
  df['text'] = df['text'].apply(util.remove_emojis)
  df['text'] = df['text'].apply(util.remove_symbols)
  df['text'] = df['text'].str.replace(util.url_pattern, '', regex=True).str.strip()
  df['text'] = df['text'].str.replace(util.mention_pattern, '', regex=True).str.strip()
  df['text'] = df['text'].str.replace('\s+', ' ', regex=True).str.strip()
  df['text'] = df['text'].replace(r'!+', '!', regex=True)
  df['text'] = df['text'].replace(r'\.+', '', regex=True)
  letters = [
  [['ሐ', 'ሑ', 'ሒ', 'ሓ', 'ሔ', 'ሖ'], ['ሀ', 'ሁ', 'ሂ', 'ሃ', 'ሄ', 'ህ', 'ሆ']],
  [['ኀ', 'ኁ', 'ኂ', 'ኃ', 'ኄ', 'ኅ', 'ኆ'], ['ሀ', 'ሁ', 'ሂ', 'ሃ', 'ሄ', 'ህ', 'ሆ']],
  [['ሠ', 'ሡ', 'ሢ', 'ሣ', 'ሤ', 'ሦ', 'ሦ', 'ሧ'], ['ሰ', 'ሱ', 'ሲ', 'ሳ', 'ሴ', 'ስ', 'ሶ', 'ሷ']],
  [['ዐ', 'ዑ', 'ዒ', 'ዓ', 'ዔ', 'ዕ', 'ዖ'], ['አ', 'ኡ', 'ኢ', 'ኣ', 'ኤ', 'እ', 'ኦ']],
  [['ጸ', 'ጹ', 'ጺ', 'ጻ', 'ጼ', 'ጽ', 'ጾ'], ['ፀ', 'ፁ', 'ፂ', 'ፃ', 'ፄ', 'ፅ', 'ፆ']]
  ]
  for letter in letters:
  for i in range(len(letter[0])):
  df['text'] = df['text'].str.replace(letter[0][i], letter[1][i])
  df['text'] = df['text'].str.replace(r'[A-Za-z]+', '', regex=True)
  cleaned_text_path = os.path.join(cleaned_files_directory, f"{os.path.splitext(filename)[0]}.txt")
  df['text'].to_csv(cleaned_text_path, index=False, header=False)

def clean_all_in_one(input_path, output_path):
  parsed_csv_path = "../data/parsed/parsed.csv"
  output_cleaned_csv_path = "../data/parsed/cleaned_parsed.csv"
 
if __name__ == "__main__":
  util = Util()
import os
import pandas as pd
from utils import Util

def parse_all_in_one():
  zip_file_path = "../data/raw/raw.zip"
  output_csv_path = "../data/parsed/parsed.csv"
  util.process_zip(zip_file_path, output_csv_path)
  print("Parsing completed. Output saved to", output_csv_path)

def parse_cleaned_individual_files():
  zip_file_path = "../data/raw/raw.zip"
  output_directory = "../data/parsed/"
  util.process_zip_files(zip_file_path, output_directory)
 
if __name__ == "__main__":
  util = Util()
  parse_all_in_one()
  parse_cleaned_individual_files()
Backend code for Amharic Ad generator.
 
This backend handles prompt generation based on user input.
 
- Python (version 3.11.7)
- Flask (install via `pip install fastapi`)
- Uvicorn (install via `pip install uvicorn`)
- ...
 
```bash
git clone https://github.com/group-3-collab-team/Amharic-RAG-Ad-Builder.git
cd backend
pip install -r requirements.txt
uvicorn main:app --reload
```
import sentencepiece as spm
 
spm.SentencePieceTrainer.train('--input=cleaned.txt --model_prefix=m --vocab_size=2000')
 
sp = spm.SentencePieceProcessor()

sp.load('m.model')
 
print(sp.encode_as_pieces('በአዲስ አበባ የአሜሪካ ኤምባሲ'))

print(sp.encode_as_ids('በአዲስ አበባ የአሜሪካ ኤምባሲ'))
 
print(sp.decode_pieces(['_በአዲስ', '_አበባ', '_የአሜሪካ', '_ኤ', 'ምባሲ']))
print(sp.decode_ids([460, 133, 774, 1276]))
 
print(sp.get_piece_size())
 
print(sp.id_to_piece(460))

print(sp.piece_to_id('▁በአዲስ'))
 
print(sp.piece_to_id('__MUST_BE_UNKNOWN__'))
 
for id in range(3):
  print(sp.id_to_piece(id), sp.is_control(id))
 
import tensorflow as tf
 
serialized_model_proto = tf.io.gfile.GFile('m.model', 'rb').read()
 
sp = spm.SentencePieceProcessor()

sp.load_from_serialized_proto(serialized_model_proto)
 
print(sp.encode_as_pieces('በአዲስ አበባ የአሜሪካ ኤምባሲ'))
 
spm.SentencePieceTrainer.train('--input=cleaned.txt --model_prefix=m_user --user_defined_symbols=<sep>,<cls> --vocab_size=2000')
 
sp_user = spm.SentencePieceProcessor()

sp_user.load('m_user.model')
 
print(sp_user.encode_as_pieces('በአዲስ አበባ የአሜሪካ<sep> ኤምባሲ<cls>'))

print(sp_user.piece_to_id('<sep>'))  
print(sp_user.piece_to_id('<cls>'))  
print('3=', sp_user.decode_ids([3]))  
print('4=', sp_user.decode_ids([4]))  
spm.SentencePieceTrainer.train('--input=cleaned.txt --model_prefix=m_ctrl --control_symbols=<sep>,<cls> --vocab_size=2000')
 
sp_ctrl = spm.SentencePieceProcessor()

sp_ctrl.load('m_ctrl.model')
 
print(sp_ctrl.encode_as_pieces('በአዲስ አበባ የአሜሪካ<sep>ኤምባሲ<cls>'))

print(sp_ctrl.piece_to_id('<sep>'))  
print(sp_ctrl.piece_to_id('<cls>'))  
print('3=', sp_ctrl.decode_ids([3]))  
print('4=', sp_ctrl.decode_ids([4]))  spm.SentencePieceTrainer.train('--input=cleaned.txt --model_prefix=m_bos_as_user --user_defined_symbols=<s>,</s> --vocab_size=2000')
 
sp = spm.SentencePieceProcessor()

sp.load('m.model')

print(sp.encode_as_pieces('<s> በአዲስ</s>'))  
sp = spm.SentencePieceProcessor()

sp.load('m_bos_as_user.model')

print(sp.encode_as_pieces('<s> በአዲስ</s>'))  
spm.SentencePieceTrainer.train('--input=cleaned.txt --model_prefix=m --vocab_size=2000')
 
sp = spm.SentencePieceProcessor()

sp.load('m.model')
 
print('bos=', sp.bos_id())

print('eos=', sp.eos_id())

print('unk=', sp.unk_id())

print('pad=', sp.pad_id())  
print(sp.encode_as_ids('በአዲስ አበባ'))
 
print([sp.bos_id()] + sp.encode_as_ids('በአዲስ አበባ') + [sp.eos_id()])
 
spm.SentencePieceTrainer.train('--input=cleaned.txt --model_prefix=m --vocab_size=2000')
 
for n in range(10):
  print(sp.sample_encode_as_pieces('በአዲስ አበባ', -1, 0.1))
 
for n in range(10):
  print(sp.sample_encode_as_ids('በአዲስ አበባ', -1, 0.1))

print(sp.nbest_encode_as_pieces('በአዲስ አበባ', 10))

print(sp.nbest_encode_as_ids('በአዲስ አበባ', 10))
 
spm.SentencePieceTrainer.train('--input=cleaned.txt --model_prefix=m_bpe --vocab_size=2000 --model_type=bpe')

sp_bpe = spm.SentencePieceProcessor()

sp_bpe.load('m_bpe.model')
 
print('*** BPE ***')

print(sp_bpe.encode_as_pieces('በአዲስአበባየአሜሪካኤምባሲ'))

print(sp_bpe.nbest_encode_as_pieces('በአዲስ አበባ', 5))  spm.SentencePieceTrainer.train('--input=TIKVAH.txt --model_prefix=m_unigram --vocab_size=2000 --model_type=unigram')

sp_unigram = spm.SentencePieceProcessor()

sp_unigram.load('m_unigram.model')
 
print('*** Unigram ***')

print(sp_unigram.encode_as_pieces('በአዲስአበባየአሜሪካኤምባሲ'))

print(sp_unigram.nbest_encode_as_pieces('በአዲስአበባየአሜሪካኤምባሲ', 5))
import json

from langchain.document_loaders import TextLoader
from langchain.text_splitter import CharacterTextSplitter  
from langchain.chat_models import ChatOpenAI
from langchain.prompts import ChatPromptTemplate
from langchain.schema.runnable import RunnablePassthrough
from langchain.schema.output_parser import StrOutputParser
from langchain.embeddings import OpenAIEmbeddings
from langchain.vectorstores import Weaviate
import logging
from typing import List, Optional, Union
from langchain.prompts import PromptTemplate
from transformers import pipeline
 
import transformers
from sentence_transformers import SentenceTransformer
 
from datasets import Dataset

import weaviate
from dotenv import load_dotenv,find_dotenv
from weaviate.embedded import EmbeddedOptions
 
load_dotenv(find_dotenv())

logger = logging.getLogger(__name__)

def data_loader(file_path: str, chunk_size: int = 500, chunk_overlap: int = 50) -> Union[List[str], None]:
  """
  Load data from a file, split it into chunks, and return the chunks.
  Parameters:
  - file_path (str): The path to the file containing the data.
  - chunk_size (int): The size of each data chunk. Default is 500.
  - database (int): The overlap between consecutive chunks. Default is 50.
  Returns:
  - list: A list of data chunks.
  """
  try:
  loader = TextLoader(file_path)
  documents = loader.load()
  text_splitter = CharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)
  chunks = text_splitter.split_documents(documents)
  logger.info("Data loaded to vector database successfully")
  return chunks
  except Exception as e:
  logger.error(f"An unexpected error occurred: {e}")
  return None  
def create_retriever(chunks, model):
  try:
  load_dotenv(find_dotenv())
  client = weaviate.Client(embedded_options=EmbeddedOptions())
  vectorstore = Weaviate.from_documents(
  client=client,
  documents=chunks,
  embedding=model.encode,   by_text=False
  )
  retriever = vectorstore.as_retriever()
  print("Retriever created successfully.")
  return retriever
  except Exception as e:
  print(f"An unexpected error occurred: {e}")
  return None
 
def create_langchain_pipeline(retriever, template, temperature=0, model_name="meta-llama/Llama-2-7b-chat-hf"):
  try:
  model_name = "meta-llama/Llama-2-7b-chat-hf"
  token = "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"
  llm = pipeline("text-generation", model=model_name, temperature=temperature)
  prompt = PromptTemplate.from_template(template)
  rag_chain = (
  {"context": retriever, "question": RunnablePassthrough()}
  | prompt
  | llm
  | StrOutputParser()
  )
  print("Langchain with RAG pipeline created successfully.")
  return rag_chain
  except Exception as e:
  print(f"An unexpected error occurred: {e}")
  return None
 
def generate_testcase_and_context(questions, ground_truths, retriever, rag_chain):
  try:
  answers = []
  contexts = []
  for query in questions:
  answers.append(rag_chain.invoke(query))
  contexts.append([docs.page_content for docs in retriever.get_relevant_documents(query)])
  data = {
  "question": questions,   "answer": answers,   "contexts": contexts,   "ground_truths": ground_truths   }
  dataset = Dataset.from_dict(data)   print("automatic evaluation data generated succesfully.")
  return  dataset
  except Exception as e:
  print(f"An unexpected error occurred: {e}")
  return None  
def load_file(file_path):
  try:
  with open(file_path, 'r') as file:
  file_contents = file.read()   return file_contents
  except Exception as e:
  print(f"An unexpected error occurred: {e}")
  return None  
def get_generated_prompt_with_evaulation(question):
  try:
  chunks = data_loader()
  retriever = create_retriever(chunks)
  prompt_template = load_file('../prompts/prompt-generation-prompt.txt')
  evaluation_tempate = load_file('../prompts/evaluation-data-generation.txt')
  prompt_rag_chain = create_langchain_pipeline(retriever, prompt_template)
  evaulation_rag_chain = create_langchain_pipeline(retriever, evaluation_tempate, temperature=0.2)
  generated_prompts = prompt_rag_chain.invoke(question)
  prompt_list  = json.loads(generated_prompts)
  questions = [item['prompt'] for item in prompt_list]
  ground_truths = [[item['ground_truth']] for item in prompt_list]
  response = generate_testcase_and_context(questions, ground_truths, retriever, evaulation_rag_chain)
  return response
  except Exception as e:
  print(f"An unexpected error occurred: {e}")
  return None
Welcome to the front-end repository of the Enterprise-Grade RAG System, built with React.js.
 
To run the development server, use one of the following commands:

```bash
npm run dev
yarn dev
npm dev
max-width: 1440px;
  margin: 0 auto;
  padding: 2rem;
  text-align: center;
}

nav{
  background-color: }
.logo {
  height: 6em;
  padding: 1.5em;
  will-change: filter;
}
.logo:hover {
  filter: drop-shadow(0 0 2em }
.logo.react:hover {
  filter: drop-shadow(0 0 2em }

@keyframes logo-spin {
  from {
  transform: rotate(0deg);
  }
  to {
  transform: rotate(360deg);
  }
}

@media (prefers-reduced-motion: no-preference) {
  a:nth-of-type(2) .logo {
  animation: logo-spin infinite 20s linear;
  }
}

.card {
  padding: 2em;
}

.read-the-docs {
  color: }
@tailwind base;
@tailwind components;
@tailwind utilities;

* {
  font-family: "Inter", sans-serif;
}

@media screen and (min-width: 480px) {
  .card:nth-child(7n + 1) {
  grid-column: auto/span 2;
  grid-row: auto/span 2;
  }
}

.prompt::-webkit-scrollbar {
  width: 5px;
}

.prompt::-webkit-scrollbar-thumb {
  background-color:   border-radius: 5px;
}

input {
  color: }

body {
  background-color: theme("colors.hero") ;
  color: theme("colors.grey");
  scroll-behavior: smooth;
  font-size: 14px;
}

.paginate,
.next,
.prev {
  border-radius: 50%;
  background-color: theme("colors.grey");
  padding: 0.2rem 0.6rem;
  font-size: 0.8rem;
  display: flex;
  justify-content: center;
  align-items: center;
  color: theme("colors.dark");
  font-weight: bold;
  margin: 0 0.1rem;
  cursor: pointer;
  transition: all 0.5s ease;
}

.next:hover,
.prev:hover,
.paginate:hover {
  color: theme("colors.brand");
}

header {
  z-index: 100;
}
.paginate.active {
  background-color: theme("colors.accent");
}
.next,
.prev {
  border-radius: 10px;
  background-color: theme("colors.grey");
}

.next:disabled,
.prev:disabled {
  background-color: theme("colors.darkgrey");
  color: theme("colors.grey");
  opacity: 0.3;
  cursor: not-allowed;
}

h1 {
  font-size: 2rem;
  font-weight: 600;
}

.hero {
  display: grid;
  grid-template-columns: 100%;
  align-items: center;
  grid-gap: 10%;
  justify-content: center;
}

.hero__img {
  width: 90%;
  height: 80%;
  position: relative;
  overflow: hidden;
  border-radius: 10px 0 0 300px;
  display: none;
}

.hero__img img {
  transition: all 0.6s ease;
  cursor: pointer;
}

.hero__img img:hover {
  transform: scale(1.2);
}

::placeholder {
  color:   font-size: 0.75rem;
}
.form {
  display: grid;
  grid-template-columns: 1fr;
  grid-gap: 2rem;
}

.form_photo {
  width: 100%;
  height: 100%;
  margin-top: auto;
}
@media screen and (min-width: 768px) {
  .form {
  grid-template-columns: 1fr 1fr;
  }
  .form_photo {
  width: 80%;
  height: 80%;
  }
  .hero {
  grid-template-columns: 40% 50%;
  }
  .hero__img {
  display: block;
  }
  h1 {
  font-size: 2.5rem;
  }
  body{
  font-size: 16px;
  }
}
import React from 'react'
import { BrowserRouter, Route, Routes, Link } from 'react-router-dom'
import { aiqem_logo } from "./assets"
import { Home, CreatePost } from "./pages"
 
const App = () => {
  return (
  <BrowserRouter>
  <header className="w-full fixed flex justify-between items-center bg-blue-800 sm:px-8 px-4 py-4 border-b border-blue-800">
  <Link to="/">
  <img src={aiqem_logo} alt="Logo" />   </Link>
  <Link to="/" className="font-inter font-medium text-white px-2 ml-auto">Home</Link>
  <Link to="/create" className="font-inter font-bold bg-blue-800 text-white px-2 py-1 rounded-md">Chat</Link>
  </header>
  <main className="py-8 w-full bg-white  min-h-[calc(100vh)]">
  <Routes>
  <Route path="/create" element={<CreatePost />} />
  <Route path="/" element={<Home />} />
  </Routes>
  </main>
  </BrowserRouter>
  )
}

export default App

//106e75
import download from "./download.png";
import aiqem_logo from "./aiqem_logo.svg";
import logo from "./aiqem_logo.svg";
import preview from "./preview.png";
import hero from "./hero.png";
import africa1 from "./africa1.jpg";
import images from "./images.jpeg"
import telegram from "./telegram.jpeg";
export { download, aiqem_logo, logo,  preview, hero, africa1 , images, telegram};
import React from 'react'
import { useState, useRef} from 'react';
import axios from "axios";

const FileUpload = () => {
  const fileInputRef = useRef(null);
  const [text, setText] = useState("");
  const handleButtonClick = () => {
  // Trigger the file input when the button is clicked
  fileInputRef.current.click();
  };
  const handleFileChange = async (event) => {
  const selectedFile = event.target.files[0];
  const formData = new FormData();
  formData.append('file', selectedFile);
  try {
  const response = await axios.post('http://127.0.0.1:5000/extract-text', formData, {
  headers: { 'Content-Type': 'multipart/form-data' },
  });
  setText(response.data.data);
  } catch (error) {
  console.error(error);
  }
  };
  return (
  <div>
  <button onClick={handleButtonClick}>
  <span role="img" aria-label="attachment">📎</span>
  </button>
  <input
  ref={fileInputRef}
  type="file"
  accept=".pdf"
  style={{ display: 'none' }}
  onChange={handleFileChange}
  />  
</div>
  )
}

export default FileUpload
import React, { useState } from "react";
import { useNavigate } from "react-router-dom";

import { preview } from "../assets";
import { getRandomPrompt } from "../utils";
import { FormFields, Loader } from "../components";
import FileUpload from "../components/FileUpload";
import { africa1 } from "../assets/index";

const CreatePost = () => {
  const navigate = useNavigate();
  const models_list = [
  {"model_name": "Llama2 Model",
  "model_type": ""
  },
  {"model_name": "Finetuned Llama2 Model",
  "model_type": ""
  },
  {"model_name": "GPT 3.5 TURBO Model",
  "model_type": "gpt-3.5-turbo"
  },
  {"model_name": "GPT 4.0 Model",
  "model_type": "gpt-4-1106-preview"
  }
  ]
  const [selectedModel, setSelectedModel] = useState(models_list[0].model_name); // Set the default selected model
  console.log(selectedModel)
  const [message, setMessage] = useState('');
  const [chatResponse, setchatResponse] = useState('');
  const submitQuery= async () => {
  if (form.scenario) {
  try {
  setGeneratingprompt(true);
  const response = await fetch(
  "https://192.168.137.236/api/generate",
  {
  method: "POST",
  headers: {
  "Content-Type": "application/json",
  },
  body: JSON.stringify({
  prompt: form.scenario,
  }),
  }
  );
  const data = await response.json();
  setForm({ ...form, preview: `data:image/jpeg;base64,${data.photo}` });
  setResult(data.result); // Set the result in the state
  } catch (err) {
  console.log(err);
  } finally {
  setGeneratingprompt(false);
  }
  } else {
  alert("Please provide a proper prompt");
  }
  };
  const handleMessageChange = (event) => {
  setMessage(event.target.value);
  };
  console.log('Submitted input:', message);
  console.log('Submitted input:', chatResponse);
  const submitInput = async () => {
  // Handle submitting the input, you can use the 'message' state here
  // Add your logic for submitting the input to the backend
  try {
  const response = await fetch(
  'https://9bba-196-189-127-38.ngrok-free.app/api/v1/chat', {
  method: 'POST',
  headers: {
  'Content-Type': 'application/json',
  },
  body: JSON.stringify({ "message":message , "model_type":models_list[selectedModel].model_type}),
  });
  if (response.ok) {
  setMessage('')
  setchatResponse(response);
  } else {
  console.error('Failed to submit input to the backend');
  }
  } catch (error) {
  console.error('Error during API call:', error);
  }
  };
  const handleSubmit = async (e) => {
  e.preventDefault();
  if (form.scenario && form.preview) {
  setLoading(true);
  try {
  const response = await fetch(
  "https://192.168.137.236/api/generate",
  {
  method: "POST",
  headers: {
  "Content-Type": "application/json",
  },
  body: JSON.stringify({ ...form}),
  }
  );
  if (response.ok) {
  const responseData = await response.json();
  // Assuming the response has a property named "result"
  const result = responseData.result;
  // Do something with the result
  console.log(result);
  // You can also update your UI or state with the received result
  } else {
  console.log("Failed to get a successful response from the server");
  }
  } catch (err) {
  console.error(err);
  } finally {
  setLoading(false);
  }
  } else {
  alert("Please generate a prompt with proper details");
  }
  };
  return (
  <section className="flex flex-row bg-white min-h-[calc(100vh)]">
  <div className="sm:hidden  md:flex md:flex-col md:w-1/3 md:flex-shrink-0 md:lg:w-[240px] md:h-[calc(100vh-120px)] md:whitespace-nowrap md:fixed bg-white md:overflow-x-hidden md:transition-all md:ease-in-out pt-2">
  <div className="flex flex-col mt-24 items-start space-y-4  md:h-full ml-[16px]">
  <label className="text-lg ml-4 font-bold text-black" id="demo-radio-buttons-group-label">
  Select Model
  </label>
  <div className="flex flex-col space-y-2 pl-2">
  {models_list.map((model, index) => (
  <div key={index}>
  <input
  type="radio"
  id={`model-${index}`}
  name="radio-buttons-group"
  value={model.model_name}
  className="mr-2"
  checked={index === selectedModel}
  onChange={() => setSelectedModel(index)}
  />
  <label htmlFor={`model-${index}`} className="text-base text-black">
  {model.model_name}
  </label>
  </div>
  ))}
  </div>
  </div>
  </div>
  {/* Main Content */}
  <div className="flex flex-col h-full md:w-3/4 px-4 py-6 sm:w-full">
  {/* Texts */}
  <div className="sm:flex sm:flex-col md:ml-[530px]  sm:ml-[100px] sm:mt-16 sm:font-extrabold sm:text-text sm:text-[42px]">
  <h1 className="md:ml-[100px] text-black sm:text-[40px] sm:ml-[160px]">አድባር</h1>
  <div className="flex justify-center space-x-6 mt-8 ml-[-4px]">
  {/* First Container */}
  <div className="md:text-3xl text-xl text-black bg-gray-100 rounded-lg p-6 shadow-md sm:max-w-[400px] md:max-w-[1600px]">
  <h2 className="font-bold ml-4">Retail</h2>
  <p className="text-gray-600">Generate Telegram Ad</p>
  </div>
  {/* Second Container */}
  <div className="md:text-3xl text-xl text-black bg-gray-100 rounded-lg p-6 shadow-md sm:max-w-[400px] md:max-w-[1600px]">
  <h2 className="font-bold ml-4">Automotive</h2>
  <p className="text-gray-600">Generate Telegram Ad</p>
  </div>
  {/* Third Container */}
  <div className="md:text-3xl text-xl text-black bg-gray-100 rounded-lg p-6 shadow-md sm:max-w-[400px] md:max-w-[1600px]">
  <h2 className="font-bold ml-4">Real Estate</h2>
  <p className="text-gray-600">Generate Telegram Ad</p>
  </div>
  </div>
  {/* <img src={ africa1 } alt="img" className="ml- -8 sm:w-[400px] sm:ml-[52px] md:ml-[2px] w-[600px]"/> */}
  </div>
  <div className="sm:flex sm:flex-col md:ml-32 sm:ml-[-40px] sm:w-3/4">
  <footer className="flex-row-2 mt-2 mb-2 border-blue-800 p-4 absolute bottom-0 ml-36 w-3/4" onSubmit={handleSubmit}>
  <label for="chat" class="sr-only">Your message</label>
  <div class="flex items-center py-2 px-3 bg-blue-800 rounded-lg dark:bg-blue-800">
  <FileUpload/>
  <div>
  <textarea
  id="chat"   rows="1"   class="block mx-4 p-2.5 w-full text-sm text-gray-900 bg-white rounded-lg border focus:ring-blue-500 focus:border-blue-500 dark:bg-white-800 dark:border-blue-800 dark:placeholder-blue-800 dark:text-black dark:focus:ring-blue-500 dark:focus:border-blue-500"
  placeholder="Your message..."
  value={message}
  onChange={handleMessageChange}
  />
  {/* Display the value (optional) */}
  <button
  type="submit"
  onClick={submitInput}
  class="inline-flex justify-center p-2 text-blue-600 rounded-full cursor-pointer hover:bg-blue-100 dark:text-blue-500 dark:hover:bg-gray-600">
  <svg
  className="w-6 h-6 rotate-90"
  fill="white"
  viewBox="0 0 20 20"
  xmlns="http://www.w3.org/2000/svg"
  >
  <path d="M10.894 2.553a1 1 0 00-1.788 0l-7 14a1 1 0 001.169 1.409l5-1.429A1 1 0 009 15.571V11a1 1 0 112 0v4.571a1 1 0 00.725.962l5 1.428a1 1 0 001.17-1.408l-7-14z"></path>
  </svg>
  </button>
  </div>
  {chatResponse && (
  <div style={{ border: '1px solid   <p>Response:</p>
  <pre>{JSON.stringify(chatResponse, null, 2)}</pre>
  </div>
  )}
  </div>
  </footer>
  </div>
  </div>
</section>
  );
};

export default CreatePost;
import React, { useState, useEffect } from "react";
import { Loader, FormFields, Card } from "../components";
import { Link } from "react-router-dom";
import { africa1, telegram } from "../assets/index";

const RenderCards = ({ data, title }) => {
  if (data?.length > 0) {
  return data.map((post) => <Card key={post._id} {...post} />);
  } else {
  return <h2 className="text-brand font-bold text-xl">{title}</h2>;
  }
};

const Home = () => {
  const [loading, setLoading] = useState(false);
  const [allPosts, setAllPosts] = useState([]);
  const [searchText, setSearchText] = useState("");
  const [filteredPosts, setFilteredPosts] = useState([]);
  const [searchTimeout, setSearchTimeout] = useState(null);
  useEffect(() => {
  const fetchPosts = async () => {
  setLoading(true);
  try {
  const response = await fetch(
  "https://dalle-hn3a.onrender.com/api/v1/post",
  {
  method: "GET",
  headers: {
  "Content-Type": "application/json",
  },
  }
  );
  if (response.ok) {
  const result = await response.json();
  setAllPosts(result.data.reverse());
  }
  } catch (err) {
  console.log(err);
  } finally {
  setLoading(false);
  }
  };
  fetchPosts();
  }, []);
  const handleSearchChange = async (e) => {
  clearTimeout(searchTimeout);
  setSearchText(e.target.value);
  setSearchTimeout(
  setTimeout(() => {
  const filteredPosts = allPosts.filter((post) =>
  post.prompt.toLowerCase().includes(searchText.toLowerCase())
  );
  setFilteredPosts(filteredPosts);
  setLoading(false);
  }, 500)
  );
  };
  // set dynamic imgPerPage value according to screen size
  if (window.innerWidth <= 768) {
  var dynamicPerPage = 3;
  } else {
  dynamicPerPage = 6;
  }
  // implement pagination
  const [currentPage, setCurrentPage] = useState(1);
  const [postsPerPage] = useState(dynamicPerPage);
  const indexOfLastPost = currentPage * postsPerPage;
  const indexOfFirstRepo = indexOfLastPost - postsPerPage;
  const currentPosts = allPosts.slice(indexOfFirstRepo, indexOfLastPost);
  const paginate = (pageNumber) => {
  setCurrentPage(pageNumber);
  window.scrollTo({ top: 0, behavior: "smooth" });
  };
  // calculate page numbers
  const pageNumbers = [];
  for (let i = 1; i <= Math.ceil(allPosts.length / postsPerPage); i++) {
  pageNumbers.push(i);
  }
  return (
  <section className="mx-auto">
  <div className="md:grid md:grid-cols-2 md:grid-flow-row md:gap-4 max-w-7xl mt-16 sm:p-8 px-4 py-8 m-auto bg-white">
  <div className="hero__text grid-col-1 flex flex-col"> <br />
  <h1 className="text-text text-blue-800">አድባር</h1>
  <p className="mt-2 text-text max-w-[520px] text-hero text-[15px]">
  Welcome to AIQEM, where innovation meets impact in the heart of African technology! 🌍
  Unleashing the power of AI and Blockchain, AIQEM proudly presents አድባር – our groundbreaking Telegram Ad solution tailored for Ethiopian businesses.
  Elevate your advertising strategy with አድባር, our end-to-end AI-based platform designed to optimize ad placements across diverse Telegram channels.
  Explore the future of marketing with AIQEM's Amharic RAG pipeline, revolutionizing the creation of engaging Amharic text Ad content for unparalleled campaign success.
  Join us on the forefront of technological innovation as we reshape the landscape of AI and Blockchain solutions for Ethiopian and African businesses. 🚀   </p>
  <br />
  <Link
  to="/create"
  className="font-inter font-bold bg-blue-800 text-white px-2 py-1 rounded-md w-[60px]"
  >
  Chat
  </Link>
  </div>
  <div className="mt-16]">
  <img src={telegram} style={{ width: 500, height: 400 }} alt="img" className=""/>
  </div>
  </div>
  </section>
  );
};

export default Home;
%import sys, os, json, re, zipfile, csv

import pandas as pd

import emoji

class Util():
  def __init__(self) -> None:
  self.emoji_pattern = re.compile(r"[\U0001F000-\U0001F9FF\U0001FA00-\U0001FFFF\U00020000-\U0002FFFF\U00030000-\U0003FFFF]+", flags=re.UNICODE)
  self.symbols = re.compile("["
  "\""
  "\“"
  "\""
  "\'"
  "\-"
  "\*"
  "\•"
  "\ℹ"
  "\﻿"
  "\_"
  "]+")
  self.url_pattern = r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+'
  self.mention_pattern = r'@(\w+)'
  def read_file(self, file_path: str) -> dict:
  with open(file_path, 'r') as file:
  data = json.load(file)
  return data
  def write_file(self, file_path: str, data: dict) -> None:
  with open(file_path, 'w') as file:
  json.dump(data, file, indent=2)
  def parse_text(self, text: any) -> str:
  if isinstance(text, str):
  return text
  elif isinstance(text, list):
  contents = []
  for item in text:
  if isinstance(item, str):
  contents.append(item)
  elif isinstance(item, dict):
  contents.append(item['text'])
  return "".join(contents)
  else:
  return ""
  def parse_messages(self, messages: list) -> dict:
  parsed_messages = {
  'id': [],
  'text': [],
  'date': []
  }
  for message in messages:
  if message['type'] != 'message' or len(message['text']) == 0:
  continue
  parsed_messages['id'].append(message['id'])
  message_content = self.parse_text(message['text'])
  parsed_messages['text'].append(message_content)
  parsed_messages['date'].append(message['date'])
  return parsed_messages
  def extract_hashtags(self, text: str) -> list:
  return [word for word in text.split() if word.startswith('
  def extract_emojis(self, text):
  return ''.join(self.emoji_pattern.findall(text))
  def remove_emojis(self, text):
  return self.emoji_pattern.sub('', text)
  def extract_symbols(self, text):
  return ''.join(self.symbols.findall(text))
  def remove_symbols(self, text):
  return self.symbols.sub(' ', text)
  def extract_urls(self, text):
  return re.findall(self.url_pattern, text)
  def extract_mentions(self, text):
  return re.findall(self.mention_pattern, text)
  def extract_fields(self, message):
  """
  Extracts relevant fields from the message.
  Returns a tuple containing (channel_id, text, date, labels).
  """
  text = ' '.join(item['text'] for item in message['text_entities'] if item['type'] in 'plain')
  date = message['date']
  labels = "LABEL"   return text, date, labels
  def process_json_file(self, json_file, csv_writer):
  """
  Processes a JSON file, extracts relevant fields, and writes to CSV.
  """
  data = json.load(json_file)
  channel_id = data['id']
  for message in data['messages']:
  text, date, labels = self.extract_fields(message)
  csv_writer.writerow([channel_id, text, date, labels])
  def process_zip(self, zip_file_path, output_csv_path):
  """
  Processes a zip file, extracts data from JSON files, and writes to a CSV file.
  """
  with zipfile.ZipFile(zip_file_path, 'r') as zip_file:
  with open(output_csv_path, 'w', newline='', encoding='utf-8') as csv_file:
  csv_writer = csv.writer(csv_file)
  csv_writer.writerow(['id', 'text', 'date', 'label'])
  for file_info in zip_file.infolist():
  with zip_file.open(file_info.filename) as json_file:
  print(json_file)
  self.process_json_file(json_file, csv_writer)
  def process_zip_files(self, zip_file_path, output_directory):
  with zipfile.ZipFile(zip_file_path, 'r') as zip_file:
  for file_info in zip_file.infolist():
  with zip_file.open(file_info.filename) as json_file:
  data = json.load(json_file)
  parsed_data = self.parse_json_data(data)
  df = pd.DataFrame(parsed_data)
  output_file_name = os.path.splitext(os.path.basename(file_info.filename))[0]
  output_csv_path = os.path.join(output_directory, f"{output_file_name}_parsed.csv")
  df.to_csv(output_csv_path, index=False)
  def parse_json_data(self, data):
  parsed_data = {
  'id': [],
  'text': [],
  'date': [],
  'label': []
  }
  for message in data['messages']:
  text, date, labels = self.extract_fields(message)
  parsed_data['id'].append(data['id'])
  parsed_data['text'].append(text)
  parsed_data['date'].append(date)
  parsed_data['label'].append(labels)
  return parsed_data
  def file_reader(self, path: str, ) -> str:
  fname = os.path.join(path)
  with open(fname, 'r') as f:
  system_message = f.read()
  return system_message

util = Util()
 
zip_file_path = "../data/raw/raw.zip"

output_csv_path = "../data/parsed/parsed.csv"
 
util.process_zip(zip_file_path, output_csv_path)

print("Parsing completed. Output saved to", output_csv_path)
 
parsed_csv_path = "../data/parsed/parsed.csv"

output_cleaned_csv_path = "../data/parsed/cleaned_parsed.csv"
 
df = pd.read_csv(parsed_csv_path)

df = df.dropna()

df.head()

df['text'] = df['text'].replace('\n', ' ', regex=True)

df.head()

df['text'] = df['text'].str.replace(r'\
df.head()
 
df['text'] = df['text'].apply(util.remove_emojis)

df.head()

df['text'] = df['text'].apply(util.remove_symbols)

df.head()

df['text'] = df['text'].str.replace(util.url_pattern, '', regex=True).str.strip()

df.head()
df['text'] = df['text'].str.replace(util.mention_pattern, '', regex=True).str.strip()

df.head()

df['text'] = df['text'].str.replace('\s+', ' ', regex=True).str.strip()

df['text'] = df['text'].replace(r'!+', '!', regex=True)

df['text'] = df['text'].replace(r'\.+', '', regex=True)

df.head()
 
letters = [
  [['ሐ', 'ሑ', 'ሒ', 'ሓ', 'ሔ', 'ሖ'], ['ሀ', 'ሁ', 'ሂ', 'ሃ', 'ሄ', 'ህ', 'ሆ']],
  [['ኀ', 'ኁ', 'ኂ', 'ኃ', 'ኄ', 'ኅ', 'ኆ'], ['ሀ', 'ሁ', 'ሂ', 'ሃ', 'ሄ', 'ህ', 'ሆ']],
  [['ሠ', 'ሡ', 'ሢ', 'ሣ', 'ሤ', 'ሦ', 'ሦ', 'ሧ'], ['ሰ', 'ሱ', 'ሲ', 'ሳ', 'ሴ', 'ስ', 'ሶ', 'ሷ']],
  [['ዐ', 'ዑ', 'ዒ', 'ዓ', 'ዔ', 'ዕ', 'ዖ'], ['አ', 'ኡ', 'ኢ', 'ኣ', 'ኤ', 'እ', 'ኦ']],
  [['ጸ', 'ጹ', 'ጺ', 'ጻ', 'ጼ', 'ጽ', 'ጾ'], ['ፀ', 'ፁ', 'ፂ', 'ፃ', 'ፄ', 'ፅ', 'ፆ']]

]
 
for letter in letters:
  for i in range(len(letter[0])):
  df['text'] = df['text'].str.replace(letter[0][i], letter[1][i])
 
df.head()  
df['text'] = df['text'].str.replace(r'[A-Za-z]+', '', regex=True)

df.head()

cleaned_output_path = "../data/parsed/cleaned_parsed_data.csv"

df.to_csv(cleaned_output_path, index=False)

output_text_path = "../data/cleaned/cleaned.txt"

df['text'] = df['text'].apply(util.remove_emojis)

df['text'].to_csv(output_text_path, index=False, header=False, sep='\t')
zip_file_path = "../data/raw/raw.zip"

output_directory = "../data/parsed/"

util.process_zip_files(zip_file_path, output_directory)
import os

import pandas as pd
 
parsed_files_directory = "../data/parsed/"

cleaned_files_directory = "../data/cleaned/"
 
for filename in os.listdir(parsed_files_directory):
  if filename.endswith("_parsed.csv"):
  filepath = os.path.join(parsed_files_directory, filename)
  df = pd.read_csv(filepath)
  df = df.dropna()
  df['text'] = df['text'].replace('\n', ' ', regex=True)
  df['text'] = df['text'].str.replace(r'\
  df['text'] = df['text'].apply(util.remove_emojis)
  df['text'] = df['text'].apply(util.remove_symbols)
  df['text'] = df['text'].str.replace(util.url_pattern, '', regex=True).str.strip()
  df['text'] = df['text'].str.replace(util.mention_pattern, '', regex=True).str.strip()
  df['text'] = df['text'].str.replace('\s+', ' ', regex=True).str.strip()
  df['text'] = df['text'].replace(r'!+', '!', regex=True)
  df['text'] = df['text'].replace(r'\.+', '', regex=True)
  letters = [
  [['ሐ', 'ሑ', 'ሒ', 'ሓ', 'ሔ', 'ሖ'], ['ሀ', 'ሁ', 'ሂ', 'ሃ', 'ሄ', 'ህ', 'ሆ']],
  [['ኀ', 'ኁ', 'ኂ', 'ኃ', 'ኄ', 'ኅ', 'ኆ'], ['ሀ', 'ሁ', 'ሂ', 'ሃ', 'ሄ', 'ህ', 'ሆ']],
  [['ሠ', 'ሡ', 'ሢ', 'ሣ', 'ሤ', 'ሦ', 'ሦ', 'ሧ'], ['ሰ', 'ሱ', 'ሲ', 'ሳ', 'ሴ', 'ስ', 'ሶ', 'ሷ']],
  [['ዐ', 'ዑ', 'ዒ', 'ዓ', 'ዔ', 'ዕ', 'ዖ'], ['አ', 'ኡ', 'ኢ', 'ኣ', 'ኤ', 'እ', 'ኦ']],
  [['ጸ', 'ጹ', 'ጺ', 'ጻ', 'ጼ', 'ጽ', 'ጾ'], ['ፀ', 'ፁ', 'ፂ', 'ፃ', 'ፄ', 'ፅ', 'ፆ']]
  ]
  for letter in letters:
  for i in range(len(letter[0])):
  df['text'] = df['text'].str.replace(letter[0][i], letter[1][i])
  df['text'] = df['text'].str.replace(r'[A-Za-z]+', '', regex=True)
  df.to_csv(filepath, index=False)
  cleaned_text_path = os.path.join(cleaned_files_directory, f"{os.path.splitext(filename)[0]}.txt")
  df['text'].to_csv(cleaned_text_path, index=False, header=False)
import os
import pandas as pd
from utils import Util

def clean(filepath):
  df = pd.read_csv(filepath)
  df = df.dropna()
  df['text'] = df['text'].replace('\n', ' ', regex=True)
  df['text'] = df['text'].str.replace(r'\
  df['text'] = df['text'].apply(util.remove_emojis)
  df['text'] = df['text'].apply(util.remove_symbols)
  df['text'] = df['text'].str.replace(util.url_pattern, '', regex=True).str.strip()
  df['text'] = df['text'].str.replace(util.mention_pattern, '', regex=True).str.strip()
  df['text'] = df['text'].str.replace('\s+', ' ', regex=True).str.strip()
  df['text'] = df['text'].replace(r'!+', '!', regex=True)
  df['text'] = df['text'].replace(r'\.+', '', regex=True)
  letters = [
  [['ሐ', 'ሑ', 'ሒ', 'ሓ', 'ሔ', 'ሖ'], ['ሀ', 'ሁ', 'ሂ', 'ሃ', 'ሄ', 'ህ', 'ሆ']],
  [['ኀ', 'ኁ', 'ኂ', 'ኃ', 'ኄ', 'ኅ', 'ኆ'], ['ሀ', 'ሁ', 'ሂ', 'ሃ', 'ሄ', 'ህ', 'ሆ']],
  [['ሠ', 'ሡ', 'ሢ', 'ሣ', 'ሤ', 'ሦ', 'ሦ', 'ሧ'], ['ሰ', 'ሱ', 'ሲ', 'ሳ', 'ሴ', 'ስ', 'ሶ', 'ሷ']],
  [['ዐ', 'ዑ', 'ዒ', 'ዓ', 'ዔ', 'ዕ', 'ዖ'], ['አ', 'ኡ', 'ኢ', 'ኣ', 'ኤ', 'እ', 'ኦ']],
  [['ጸ', 'ጹ', 'ጺ', 'ጻ', 'ጼ', 'ጽ', 'ጾ'], ['ፀ', 'ፁ', 'ፂ', 'ፃ', 'ፄ', 'ፅ', 'ፆ']]
  ]
  for letter in letters:
  for i in range(len(letter[0])):
  df['text'] = df['text'].str.replace(letter[0][i], letter[1][i])
  df['text'] = df['text'].str.replace(r'[A-Za-z]+', '', regex=True)
  cleaned_text_path = os.path.join(cleaned_files_directory, f"{os.path.splitext(filename)[0]}.txt")
  df['text'].to_csv(cleaned_text_path, index=False, header=False)

def clean_all_in_one(input_path, output_path):
  parsed_csv_path = "../data/parsed/parsed.csv"
  output_cleaned_csv_path = "../data/parsed/cleaned_parsed.csv"
 
if __name__ == "__main__":
  util = Util()
import os
import pandas as pd
from utils import Util

def parse_all_in_one():
  zip_file_path = "../data/raw/raw.zip"
  output_csv_path = "../data/parsed/parsed.csv"
  util.process_zip(zip_file_path, output_csv_path)
  print("Parsing completed. Output saved to", output_csv_path)

def parse_cleaned_individual_files():
  zip_file_path = "../data/raw/raw.zip"
  output_directory = "../data/parsed/"
  util.process_zip_files(zip_file_path, output_directory)
 
if __name__ == "__main__":
  util = Util()
  parse_all_in_one()
  parse_cleaned_individual_files()
Backend code for Amharic Ad generator.
 
This backend handles prompt generation based on user input.
 
- Python (version 3.11.7)
- Flask (install via `pip install fastapi`)
- Uvicorn (install via `pip install uvicorn`)
- ...
 
```bash
git clone https://github.com/group-3-collab-team/Amharic-RAG-Ad-Builder.git
cd backend
pip install -r requirements.txt
uvicorn main:app --reload
```
import sentencepiece as spm
 
spm.SentencePieceTrainer.train('--input=cleaned.txt --model_prefix=m --vocab_size=2000')
 
sp = spm.SentencePieceProcessor()

sp.load('m.model')
 
print(sp.encode_as_pieces('በአዲስ አበባ የአሜሪካ ኤምባሲ'))

print(sp.encode_as_ids('በአዲስ አበባ የአሜሪካ ኤምባሲ'))
 
print(sp.decode_pieces(['_በአዲስ', '_አበባ', '_የአሜሪካ', '_ኤ', 'ምባሲ']))
print(sp.decode_ids([460, 133, 774, 1276]))
 
print(sp.get_piece_size())
 
print(sp.id_to_piece(460))

print(sp.piece_to_id('▁በአዲስ'))
 
print(sp.piece_to_id('__MUST_BE_UNKNOWN__'))
 
for id in range(3):
  print(sp.id_to_piece(id), sp.is_control(id))
 
import tensorflow as tf
 
serialized_model_proto = tf.io.gfile.GFile('m.model', 'rb').read()
 
sp = spm.SentencePieceProcessor()

sp.load_from_serialized_proto(serialized_model_proto)
 
print(sp.encode_as_pieces('በአዲስ አበባ የአሜሪካ ኤምባሲ'))
 
spm.SentencePieceTrainer.train('--input=cleaned.txt --model_prefix=m_user --user_defined_symbols=<sep>,<cls> --vocab_size=2000')
 
sp_user = spm.SentencePieceProcessor()

sp_user.load('m_user.model')
 
print(sp_user.encode_as_pieces('በአዲስ አበባ የአሜሪካ<sep> ኤምባሲ<cls>'))

print(sp_user.piece_to_id('<sep>'))  
print(sp_user.piece_to_id('<cls>'))  
print('3=', sp_user.decode_ids([3]))  
print('4=', sp_user.decode_ids([4]))  
spm.SentencePieceTrainer.train('--input=cleaned.txt --model_prefix=m_ctrl --control_symbols=<sep>,<cls> --vocab_size=2000')
 
sp_ctrl = spm.SentencePieceProcessor()

sp_ctrl.load('m_ctrl.model')
 
print(sp_ctrl.encode_as_pieces('በአዲስ አበባ የአሜሪካ<sep>ኤምባሲ<cls>'))

print(sp_ctrl.piece_to_id('<sep>'))  
print(sp_ctrl.piece_to_id('<cls>'))  
print('3=', sp_ctrl.decode_ids([3]))  
print('4=', sp_ctrl.decode_ids([4]))  spm.SentencePieceTrainer.train('--input=cleaned.txt --model_prefix=m_bos_as_user --user_defined_symbols=<s>,</s> --vocab_size=2000')
 
sp = spm.SentencePieceProcessor()

sp.load('m.model')

print(sp.encode_as_pieces('<s> በአዲስ</s>'))  
sp = spm.SentencePieceProcessor()

sp.load('m_bos_as_user.model')

print(sp.encode_as_pieces('<s> በአዲስ</s>'))  
spm.SentencePieceTrainer.train('--input=cleaned.txt --model_prefix=m --vocab_size=2000')
 
sp = spm.SentencePieceProcessor()

sp.load('m.model')
 
print('bos=', sp.bos_id())

print('eos=', sp.eos_id())

print('unk=', sp.unk_id())

print('pad=', sp.pad_id())  
print(sp.encode_as_ids('በአዲስ አበባ'))
 
print([sp.bos_id()] + sp.encode_as_ids('በአዲስ አበባ') + [sp.eos_id()])
 
spm.SentencePieceTrainer.train('--input=cleaned.txt --model_prefix=m --vocab_size=2000')
 
for n in range(10):
  print(sp.sample_encode_as_pieces('በአዲስ አበባ', -1, 0.1))
 
for n in range(10):
  print(sp.sample_encode_as_ids('በአዲስ አበባ', -1, 0.1))

print(sp.nbest_encode_as_pieces('በአዲስ አበባ', 10))

print(sp.nbest_encode_as_ids('በአዲስ አበባ', 10))
 
spm.SentencePieceTrainer.train('--input=cleaned.txt --model_prefix=m_bpe --vocab_size=2000 --model_type=bpe')

sp_bpe = spm.SentencePieceProcessor()

sp_bpe.load('m_bpe.model')
 
print('*** BPE ***')

print(sp_bpe.encode_as_pieces('በአዲስአበባየአሜሪካኤምባሲ'))

print(sp_bpe.nbest_encode_as_pieces('በአዲስ አበባ', 5))  spm.SentencePieceTrainer.train('--input=TIKVAH.txt --model_prefix=m_unigram --vocab_size=2000 --model_type=unigram')

sp_unigram = spm.SentencePieceProcessor()

sp_unigram.load('m_unigram.model')
 
print('*** Unigram ***')

print(sp_unigram.encode_as_pieces('በአዲስአበባየአሜሪካኤምባሲ'))

print(sp_unigram.nbest_encode_as_pieces('በአዲስአበባየአሜሪካኤምባሲ', 5))
import json

from langchain.document_loaders import TextLoader
from langchain.text_splitter import CharacterTextSplitter  
from langchain.chat_models import ChatOpenAI
from langchain.prompts import ChatPromptTemplate
from langchain.schema.runnable import RunnablePassthrough
from langchain.schema.output_parser import StrOutputParser
from langchain.embeddings import OpenAIEmbeddings
from langchain.vectorstores import Weaviate
import logging
from typing import List, Optional, Union
from langchain.prompts import PromptTemplate
from transformers import pipeline
 
import transformers
from sentence_transformers import SentenceTransformer
 
from datasets import Dataset

import weaviate
from dotenv import load_dotenv,find_dotenv
from weaviate.embedded import EmbeddedOptions
 
load_dotenv(find_dotenv())

logger = logging.getLogger(__name__)

def data_loader(file_path: str, chunk_size: int = 500, chunk_overlap: int = 50) -> Union[List[str], None]:
  """
  Load data from a file, split it into chunks, and return the chunks.
  Parameters:
  - file_path (str): The path to the file containing the data.
  - chunk_size (int): The size of each data chunk. Default is 500.
  - database (int): The overlap between consecutive chunks. Default is 50.
  Returns:
  - list: A list of data chunks.
  """
  try:
  loader = TextLoader(file_path)
  documents = loader.load()
  text_splitter = CharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)
  chunks = text_splitter.split_documents(documents)
  logger.info("Data loaded to vector database successfully")
  return chunks
  except Exception as e:
  logger.error(f"An unexpected error occurred: {e}")
  return None  
def create_retriever(chunks, model):
  try:
  load_dotenv(find_dotenv())
  client = weaviate.Client(embedded_options=EmbeddedOptions())
  vectorstore = Weaviate.from_documents(
  client=client,
  documents=chunks,
  embedding=model.encode,   by_text=False
  )
  retriever = vectorstore.as_retriever()
  print("Retriever created successfully.")
  return retriever
  except Exception as e:
  print(f"An unexpected error occurred: {e}")
  return None
 
def create_langchain_pipeline(retriever, template, temperature=0, model_name="meta-llama/Llama-2-7b-chat-hf"):
  try:
  model_name = "meta-llama/Llama-2-7b-chat-hf"
  token = "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"
  llm = pipeline("text-generation", model=model_name, temperature=temperature)
  prompt = PromptTemplate.from_template(template)
  rag_chain = (
  {"context": retriever, "question": RunnablePassthrough()}
  | prompt
  | llm
  | StrOutputParser()
  )
  print("Langchain with RAG pipeline created successfully.")
  return rag_chain
  except Exception as e:
  print(f"An unexpected error occurred: {e}")
  return None
 
def generate_testcase_and_context(questions, ground_truths, retriever, rag_chain):
  try:
  answers = []
  contexts = []
  for query in questions:
  answers.append(rag_chain.invoke(query))
  contexts.append([docs.page_content for docs in retriever.get_relevant_documents(query)])
  data = {
  "question": questions,   "answer": answers,   "contexts": contexts,   "ground_truths": ground_truths   }
  dataset = Dataset.from_dict(data)   print("automatic evaluation data generated succesfully.")
  return  dataset
  except Exception as e:
  print(f"An unexpected error occurred: {e}")
  return None  
def load_file(file_path):
  try:
  with open(file_path, 'r') as file:
  file_contents = file.read()   return file_contents
  except Exception as e:
  print(f"An unexpected error occurred: {e}")
  return None  
def get_generated_prompt_with_evaulation(question):
  try:
  chunks = data_loader()
  retriever = create_retriever(chunks)
  prompt_template = load_file('../prompts/prompt-generation-prompt.txt')
  evaluation_tempate = load_file('../prompts/evaluation-data-generation.txt')
  prompt_rag_chain = create_langchain_pipeline(retriever, prompt_template)
  evaulation_rag_chain = create_langchain_pipeline(retriever, evaluation_tempate, temperature=0.2)
  generated_prompts = prompt_rag_chain.invoke(question)
  prompt_list  = json.loads(generated_prompts)
  questions = [item['prompt'] for item in prompt_list]
  ground_truths = [[item['ground_truth']] for item in prompt_list]
  response = generate_testcase_and_context(questions, ground_truths, retriever, evaulation_rag_chain)
  return response
  except Exception as e:
  print(f"An unexpected error occurred: {e}")
  return None
Welcome to the front-end repository of the Enterprise-Grade RAG System, built with React.js.
 
To run the development server, use one of the following commands:

```bash
npm run dev
yarn dev
npm dev
max-width: 1440px;
  margin: 0 auto;
  /* padding: 2rem; */
  text-align: center;
}

nav{
  background-color: }
.logo {
  height: 6em;
  padding: 1.5em;
  will-change: filter;
}
.logo:hover {
  filter: drop-shadow(0 0 2em }
.logo.react:hover {
  filter: drop-shadow(0 0 2em }

@keyframes logo-spin {
  from {
  transform: rotate(0deg);
  }
  to {
  transform: rotate(360deg);
  }
}

@media (prefers-reduced-motion: no-preference) {
  a:nth-of-type(2) .logo {
  animation: logo-spin infinite 20s linear;
  }
}

.card {
  padding: 2em;
}

.read-the-docs {
  color: }
@tailwind base;
@tailwind components;
@tailwind utilities;

* {
  font-family: "Inter", sans-serif;
}

@media screen and (min-width: 480px) {
  .card:nth-child(7n + 1) {
  grid-column: auto/span 2;
  grid-row: auto/span 2;
  }
}

.prompt::-webkit-scrollbar {
  width: 5px;
}

.prompt::-webkit-scrollbar-thumb {
  background-color:   border-radius: 5px;
}

input {
  color: }

body {
  background-color: theme("colors.hero") ;
  color: theme("colors.grey");
  scroll-behavior: smooth;
  font-size: 14px;
}

.paginate,
.next,
.prev {
  border-radius: 50%;
  background-color: theme("colors.grey");
  padding: 0.2rem 0.6rem;
  font-size: 0.8rem;
  display: flex;
  justify-content: center;
  align-items: center;
  color: theme("colors.dark");
  font-weight: bold;
  margin: 0 0.1rem;
  cursor: pointer;
  transition: all 0.5s ease;
}

.next:hover,
.prev:hover,
.paginate:hover {
  color: theme("colors.brand");
}

header {
  z-index: 100;
}
.paginate.active {
  background-color: theme("colors.accent");
}
.next,
.prev {
  border-radius: 10px;
  background-color: theme("colors.grey");
}

.next:disabled,
.prev:disabled {
  background-color: theme("colors.darkgrey");
  color: theme("colors.grey");
  opacity: 0.3;
  cursor: not-allowed;
}

h1 {
  font-size: 2rem;
  font-weight: 600;
}

.hero {
  display: grid;
  grid-template-columns: 100%;
  align-items: center;
  grid-gap: 10%;
  justify-content: center;
}

.hero__img {
  width: 90%;
  height: 80%;
  position: relative;
  overflow: hidden;
  border-radius: 10px 0 0 300px;
  display: none;
}

.hero__img img {
  transition: all 0.6s ease;
  cursor: pointer;
}

.hero__img img:hover {
  transform: scale(1.2);
}

::placeholder {
  color:   font-size: 0.75rem;
}
.form {
  display: grid;
  grid-template-columns: 1fr;
  grid-gap: 2rem;
}

.form_photo {
  width: 100%;
  height: 100%;
  margin-top: auto;
}
@media screen and (min-width: 768px) {
  .form {
  grid-template-columns: 1fr 1fr;
  }
  .form_photo {
  width: 80%;
  height: 80%;
  }
  .hero {
  grid-template-columns: 40% 50%;
  }
  .hero__img {
  display: block;
  }
  h1 {
  font-size: 2.5rem;
  }
  body{
  font-size: 16px;
  }
}
import React from 'react'
import { BrowserRouter, Route, Routes, Link } from 'react-router-dom'
import { aiqem_logo } from "./assets"
import { Home, CreatePost } from "./pages"
import ChatPage from './pages/ChatPage'
 
const App = () => {
  return (
  <BrowserRouter>
  <header className="w-full fixed flex justify-between items-center bg-blue-800 sm:px-8 px-4 py-4 border-b border-blue-800">
  <Link to="/">
  <img src={aiqem_logo} alt="Logo" />   </Link>
  <Link to="/" className="font-inter font-medium text-white px-2 ml-auto">Home</Link>
  <Link to="/create" className="font-inter font-bold bg-blue-800 text-white px-2 py-1 rounded-md">Chat</Link>
  </header>
  <main className="py-8 w-full bg-white  min-h-[calc(100vh)]">
  <Routes>
  <Route path="/create" element={<CreatePost />} />
  <Route path="/" element={<Home />} />
  {/* <Route path="/chat" element={<ChatPage />} /> */}
  </Routes>
  </main>
  </BrowserRouter>
  )
}

export default App

//106e75
import download from "./download.png";
import aiqem_logo from "./aiqem_logo.svg";
import logo from "./aiqem_logo.svg";
import preview from "./preview.png";
import hero from "./hero.png";
import africa1 from "./africa1.jpg";
import images from "./images.jpeg"
import telegram from "./telegram.jpeg";
export { download, aiqem_logo, logo,  preview, hero, africa1 , images, telegram};
import React from 'react'
import { useState, useRef} from 'react';
import axios from "axios";

const FileUpload = () => {
  const fileInputRef = useRef(null);
  const [text, setText] = useState("");
  const handleButtonClick = () => {
  // Trigger the file input when the button is clicked
  fileInputRef.current.click();
  };
  const handleFileChange = async (event) => {
  const selectedFile = event.target.files[0];
  const formData = new FormData();
  formData.append('file', selectedFile);
  try {
  const response = await axios.post('http://127.0.0.1:5000/extract-text', formData, {
  headers: { 'Content-Type': 'multipart/form-data' },
  });
  setText(response.data.data);
  } catch (error) {
  console.error(error);
  }
  };
  return (
  <div>
  <button onClick={handleButtonClick}>
  <span role="img" aria-label="attachment">📎</span>
  </button>
  <input
  ref={fileInputRef}
  type="file"
  accept=".pdf"
  style={{ display: 'none' }}
  onChange={handleFileChange}
  />  
</div>
  )
}

export default FileUpload
import React, { useState } from "react";
import { useNavigate } from "react-router-dom";

import { preview } from "../assets";
import { getRandomPrompt } from "../utils";
import { FormFields, Loader } from "../components";
import FileUpload from "../components/FileUpload";
import { africa1 } from "../assets/index";
import ChatPage from "./ChatPage";

const CreatePost = () => {
  const navigate = useNavigate();
  const models_list = [
  {"model_name": "Llama2 Model",
  "model_type": ""
  },
  {"model_name": "Finetuned Llama2 Model",
  "model_type": ""
  },
  {"model_name": "GPT 3.5 TURBO Model",
  "model_type": "gpt-3.5-turbo"
  },
  {"model_name": "GPT 4.0 Model",
  "model_type": "gpt-4-1106-preview"
  }
  ]
  const [selectedModel, setSelectedModel] = useState(models_list[0].model_name); // Set the default selected model
  console.log(selectedModel)
  const [message, setMessage] = useState('');
  const [chatResponse, setchatResponse] = useState('');
  console.log("selectedModel create page: ", selectedModel)
  const submitQuery= async () => {
  if (form.scenario) {
  try {
  setGeneratingprompt(true);
  const response = await fetch(
  "https://192.168.137.236/api/generate",
  {
  method: "POST",
  headers: {
  "Content-Type": "application/json",
  },
  body: JSON.stringify({
  prompt: form.scenario,
  }),
  }
  );
  const data = await response.json();
  setForm({ ...form, preview: `data:image/jpeg;base64,${data.photo}` });
  setResult(data.result); // Set the result in the state
  } catch (err) {
  console.log(err);
  } finally {
  setGeneratingprompt(false);
  }
  } else {
  alert("Please provide a proper prompt");
  }
  };
  const handleMessageChange = (event) => {
  setMessage(event.target.value);
  };
  console.log('Submitted input:', message);
  console.log('Submitted input:', chatResponse);
  const submitInput = async () => {
  // Handle submitting the input, you can use the 'message' state here
  // Add your logic for submitting the input to the backend
  try {
  const response = await fetch(
  'https://9bba-196-189-127-38.ngrok-free.app/api/v1/chat', {
  method: 'POST',
  headers: {
  'Content-Type': 'application/json',
  },
  body: JSON.stringify({ "message":message , "model_type":models_list[selectedModel].model_type}),
  });
  if (response.ok) {
  setMessage('')
  setchatResponse(response);
  } else {
  console.error('Failed to submit input to the backend');
  }
  } catch (error) {
  console.error('Error during API call:', error);
  }
  };
  const handleSubmit = async (e) => {
  e.preventDefault();
  if (form.scenario && form.preview) {
  setLoading(true);
  try {
  const response = await fetch(
  "https://192.168.137.236/api/generate",
  {
  method: "POST",
  headers: {
  "Content-Type": "application/json",
  },
  body: JSON.stringify({ ...form}),
  }
  );
  if (response.ok) {
  const responseData = await response.json();
  // Assuming the response has a property named "result"
  const result = responseData.result;
  // Do something with the result
  console.log(result);
  // You can also update your UI or state with the received result
  } else {
  console.log("Failed to get a successful response from the server");
  }
  } catch (err) {
  console.error(err);
  } finally {
  setLoading(false);
  }
  } else {
  alert("Please generate a prompt with proper details");
  }
  };
  return (
  <section className="flex flex-row bg-white min-h-[calc(100vh)]">
  <div className="sm:hidden  md:flex md:flex-col md:w-1/3 md:flex-shrink-0 md:lg:w-[240px] md:h-[calc(100vh-120px)] md:whitespace-nowrap md:fixed bg-white md:overflow-x-hidden md:transition-all md:ease-in-out pt-2">
  <div className="flex flex-col mt-24 items-start space-y-4  md:h-full ml-[16px]">
  <label className="text-lg ml-4 font-bold text-black" id="demo-radio-buttons-group-label">
  Select Model
  </label>
  <div className="flex flex-col space-y-2 pl-2 items-start">
  {models_list.map((model, index) => (
  <div key={index}>
  <input
  type="radio"
  id={`model-${index}`}
  name="radio-buttons-group"
  value={model.model_name}
  className="mr-2"
  checked={index === selectedModel}
  onChange={() => setSelectedModel(index)}
  />
  <label htmlFor={`model-${index}`} className="text-base text-black">
  {model.model_name}
  </label>
  </div>
  ))}
  </div>
  </div>
  </div>
  {/* Main Content */}
  <div className="flex flex-col h-full md:w-3/4 px-4 py-6 sm:w-full">
  {/* <div className="sm:flex sm:flex-col md:ml-[530px]  sm:ml-[100px] sm:mt-16 sm:font-extrabold sm:text-text sm:text-[42px]">
  <h1 className="md:ml-[100px] text-black sm:text-[40px] sm:ml-[160px]">አድባር</h1>
  <div className="flex justify-center space-x-6 mt-8 ml-[-4px]">
  <div className="md:text-3xl text-xl text-black bg-gray-100 rounded-lg p-6 shadow-md sm:max-w-[400px] md:max-w-[1600px]">
  <h2 className="font-bold ml-4">Retail</h2>
  <p className="text-gray-600">Generate Telegram Ad</p>
  </div>
  <div className="md:text-3xl text-xl text-black bg-gray-100 rounded-lg p-6 shadow-md sm:max-w-[400px] md:max-w-[1600px]">
  <h2 className="font-bold ml-4">Automotive</h2>
  <p className="text-gray-600">Generate Telegram Ad</p>
  </div>
  <div className="md:text-3xl text-xl text-black bg-gray-100 rounded-lg p-6 shadow-md sm:max-w-[400px] md:max-w-[1600px]">
  <h2 className="font-bold ml-4">Real Estate</h2>
  <p className="text-gray-600">Generate Telegram Ad</p>
  </div>
  </div>
  </div> */}
  <ChatPage selectedModel={selectedModel} />
 
{/*   <div className="sm:flex sm:flex-col md:ml-32 sm:ml-[-40px] sm:w-3/4">
  <footer className="flex-row-2 mt-2 mb-2 border-blue-800 p-4 absolute bottom-0 ml-36 w-3/4" onSubmit={handleSubmit}>
  <label for="chat" class="sr-only">Your message</label>
  <div class="flex items-center py-2 px-3 bg-blue-800 rounded-lg dark:bg-blue-800">
  <FileUpload/>
  <div>
  <textarea
  id="chat"   rows="1"   class="block mx-4 p-2.5 w-full text-sm text-gray-900 bg-white rounded-lg border focus:ring-blue-500 focus:border-blue-500 dark:bg-white-800 dark:border-blue-800 dark:placeholder-blue-800 dark:text-black dark:focus:ring-blue-500 dark:focus:border-blue-500"
  placeholder="Your message..."
  value={message}
  onChange={handleMessageChange}
  />
  <button
  type="submit"
  onClick={submitInput}
  class="inline-flex justify-center p-2 text-blue-600 rounded-full cursor-pointer hover:bg-blue-100 dark:text-blue-500 dark:hover:bg-gray-600">
  <svg
  className="w-6 h-6 rotate-90"
  fill="white"
  viewBox="0 0 20 20"
  xmlns="http://www.w3.org/2000/svg"
  >
  <path d="M10.894 2.553a1 1 0 00-1.788 0l-7 14a1 1 0 001.169 1.409l5-1.429A1 1 0 009 15.571V11a1 1 0 112 0v4.571a1 1 0 00.725.962l5 1.428a1 1 0 001.17-1.408l-7-14z"></path>
  </svg>
  </button>
  </div>
  {chatResponse && (
  <div style={{ border: '1px solid   <p>Response:</p>
  <pre>{JSON.stringify(chatResponse, null, 2)}</pre>
  </div>
  )}
  </div>
  </footer>
  </div> */}
  </div>
  <ChatPage/>
</section>
  );
};

export default CreatePost;
import React, { useState, useEffect } from "react";
import { Loader, FormFields, Card } from "../components";
import { Link } from "react-router-dom";
import { africa1, telegram } from "../assets/index";

const RenderCards = ({ data, title }) => {
  if (data?.length > 0) {
  return data.map((post) => <Card key={post._id} {...post} />);
  } else {
  return <h2 className="text-brand font-bold text-xl">{title}</h2>;
  }
};

const Home = () => {
  const [loading, setLoading] = useState(false);
  const [allPosts, setAllPosts] = useState([]);
  const [searchText, setSearchText] = useState("");
  const [filteredPosts, setFilteredPosts] = useState([]);
  const [searchTimeout, setSearchTimeout] = useState(null);
  useEffect(() => {
  const fetchPosts = async () => {
  setLoading(true);
  try {
  const response = await fetch(
  "https://dalle-hn3a.onrender.com/api/v1/post",
  {
  method: "GET",
  headers: {
  "Content-Type": "application/json",
  },
  }
  );
  if (response.ok) {
  const result = await response.json();
  setAllPosts(result.data.reverse());
  }
  } catch (err) {
  console.log(err);
  } finally {
  setLoading(false);
  }
  };
  fetchPosts();
  }, []);
  const handleSearchChange = async (e) => {
  clearTimeout(searchTimeout);
  setSearchText(e.target.value);
  setSearchTimeout(
  setTimeout(() => {
  const filteredPosts = allPosts.filter((post) =>
  post.prompt.toLowerCase().includes(searchText.toLowerCase())
  );
  setFilteredPosts(filteredPosts);
  setLoading(false);
  }, 500)
  );
  };
  // set dynamic imgPerPage value according to screen size
  if (window.innerWidth <= 768) {
  var dynamicPerPage = 3;
  } else {
  dynamicPerPage = 6;
  }
  // implement pagination
  const [currentPage, setCurrentPage] = useState(1);
  const [postsPerPage] = useState(dynamicPerPage);
  const indexOfLastPost = currentPage * postsPerPage;
  const indexOfFirstRepo = indexOfLastPost - postsPerPage;
  const currentPosts = allPosts.slice(indexOfFirstRepo, indexOfLastPost);
  const paginate = (pageNumber) => {
  setCurrentPage(pageNumber);
  window.scrollTo({ top: 0, behavior: "smooth" });
  };
  // calculate page numbers
  const pageNumbers = [];
  for (let i = 1; i <= Math.ceil(allPosts.length / postsPerPage); i++) {
  pageNumbers.push(i);
  }
  return (
  <section className="mx-auto">
  <div className="md:grid md:grid-cols-2 md:grid-flow-row md:gap-4 max-w-7xl mt-16 sm:p-8 px-4 py-8 m-auto bg-white">
  <div className="hero__text grid-col-1 flex flex-col"> <br />
  <h1 className="text-text text-blue-800">አድባር</h1>
  <p className="mt-2 text-text max-w-[520px] text-hero text-[15px]">
  Welcome to AIQEM, where innovation meets impact in the heart of African technology! 🌍
  Unleashing the power of AI and Blockchain, AIQEM proudly presents አድባር – our groundbreaking Telegram Ad solution tailored for Ethiopian businesses.
  Elevate your advertising strategy with አድባር, our end-to-end AI-based platform designed to optimize ad placements across diverse Telegram channels.
  Explore the future of marketing with AIQEM's Amharic RAG pipeline, revolutionizing the creation of engaging Amharic text Ad content for unparalleled campaign success.
  Join us on the forefront of technological innovation as we reshape the landscape of AI and Blockchain solutions for Ethiopian and African businesses. 🚀   </p>
  <br />
  <Link
  to="/create"
  className="font-inter font-bold bg-blue-800 text-white px-2 py-1 rounded-md w-[60px]"
  >
  Chat
  </Link>
  </div>
  <div className="mt-16]">
  <img src={telegram} style={{ width: 500, height: 400 }} alt="img" className=""/>
  </div>
  </div>
  </section>
  );
};

export default Home;
