{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pyLDAvis\n",
    "data = pd.read_csv(\"./submission.csv\")\n",
    "data = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10, 15, 32, 38, 44, 61, 65, 72])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['rubric_id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "week1 (53, 9)\n",
      "week2 (40, 9)\n",
      "week3 (8, 9)\n",
      "week5 (36, 9)\n",
      "week6 (35, 9)\n",
      "week7 (31, 9)\n",
      "week9 (31, 9)\n",
      "week10 (32, 9)\n"
     ]
    }
   ],
   "source": [
    "rubric_id_10 = data[data[\"rubric_id\"] == 10].reset_index(drop=True)\n",
    "rubric_id_15 = data[data[\"rubric_id\"] == 15].reset_index(drop=True)\n",
    "rubric_id_32 = data[data[\"rubric_id\"] == 32].reset_index(drop=True)\n",
    "rubric_id_38 = data[data[\"rubric_id\"] == 38].reset_index(drop=True)\n",
    "rubric_id_44 = data[data[\"rubric_id\"] == 44].reset_index(drop=True)\n",
    "rubric_id_61 = data[data[\"rubric_id\"] == 61].reset_index(drop=True)\n",
    "rubric_id_65 = data[data[\"rubric_id\"] == 65].reset_index(drop=True)\n",
    "rubric_id_72 = data[data[\"rubric_id\"] == 72].reset_index(drop=True)\n",
    "# Print the resulting rows\n",
    "print(\"week1\",rubric_id_10.shape) #telecom dataset\n",
    "print(\"week2\",rubric_id_15.shape) #dropped_airflowdb\n",
    "print(\"week3\",rubric_id_32.shape) #dropped_fewfiles\n",
    "print(\"week5\",rubric_id_38.shape) #algorand\n",
    "print(\"week6\",rubric_id_44.shape) #rag\n",
    "print(\"week7\",rubric_id_61.shape) #amharic finetuning\n",
    "print(\"week9\",rubric_id_65.shape) #hardhat\n",
    "print(\"week10\",rubric_id_72.shape) #image generation\n",
    "#ruburic_id_10.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "week1 (53, 9)\n",
      "week5 (36, 9)\n",
      "week6 (35, 9)\n",
      "week7 (31, 9)\n",
      "week9 (31, 9)\n",
      "week10 (32, 9)\n"
     ]
    }
   ],
   "source": [
    "week1_python = data[data[\"rubric_id\"] == 10].reset_index(drop=True)\n",
    "# rubric_id_15 = data[data[\"rubric_id\"] == 15].reset_index(drop=True)\n",
    "# rubric_id_32 = data[data[\"rubric_id\"] == 32].reset_index(drop=True)\n",
    "week5_algo = data[data[\"rubric_id\"] == 38].reset_index(drop=True)\n",
    "week6_rag = data[data[\"rubric_id\"] == 44].reset_index(drop=True)\n",
    "week7_finetune = data[data[\"rubric_id\"] == 61].reset_index(drop=True)\n",
    "week9_eth = data[data[\"rubric_id\"] == 65].reset_index(drop=True)\n",
    "week10_img_generate = data[data[\"rubric_id\"] == 72].reset_index(drop=True)\n",
    "# Print the resulting rows\n",
    "print(\"week1\",week1_python.shape) #telecom dataset\n",
    "# print(\"week2\",rubric_id_15.shape) #dropped_airflowdb\n",
    "# print(\"week3\",rubric_id_32.shape) #dropped_fewfiles\n",
    "print(\"week5\",week5_algo.shape) #algorand\n",
    "print(\"week6\",week6_rag.shape) #rag\n",
    "print(\"week7\",week7_finetune.shape) #amharic finetuning\n",
    "print(\"week9\",week9_eth.shape) #hardhat\n",
    "print(\"week10\",week10_img_generate.shape) #image generation\n",
    "#ruburic_id_10.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "code_content\n",
       "False    44\n",
       "True      9\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "week1_python['code_content'].isnull().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming your DataFrame is named \"df\" and the column is named \"column_name\"\n",
    "week1_python.dropna(subset=['code_content'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "code_content\n",
       "False    44\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "week1_python['code_content'].isnull().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace np.nan values with an empty string\n",
    "week1_python['code_content'].fillna('', inplace=True)\n",
    "# Drop a column\n",
    "columns_to_drop = ['submission_id','payload', 'rubric_id', 'rubric_type', 'next_action', 'request_origin', 'params']\n",
    "week1_python = week1_python.drop(columns_to_drop, axis=1)\n",
    "print(\"\\nDataFrame after dropping column 'C':\")\n",
    "week1_python.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>code_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>Repository Structure: '\\n' ├── top-3 socall me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>766</td>\n",
       "      <td>Repository Structure: '\\n' ├── ReadMe.md\\n├── ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>665</td>\n",
       "      <td>Repository Structure: '\\n' ├── notebooks\\n│   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>606</td>\n",
       "      <td>Repository Structure: '\\n' ├── db\\n│   ├── sql...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>699</td>\n",
       "      <td>Repository Structure: '\\n' ├── Dashboard\\n│   ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id                                       code_content\n",
       "0      619  Repository Structure: '\\n' ├── top-3 socall me...\n",
       "1      766  Repository Structure: '\\n' ├── ReadMe.md\\n├── ...\n",
       "2      665  Repository Structure: '\\n' ├── notebooks\\n│   ...\n",
       "3      606  Repository Structure: '\\n' ├── db\\n│   ├── sql...\n",
       "4      699  Repository Structure: '\\n' ├── Dashboard\\n│   ..."
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "week1_python.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_packages(text):\n",
    "    patterns = [\n",
    "    r\"### BEGIN File: \\w+\\.txt ###.*?END File: \\w+\\.txt ###\",\n",
    "    r\"### BEGIN File: (\\w+/\\w+.txt) ###.*?END File: \\1 ###\",\n",
    "    r\"### BEGIN File: (\\w+/\\w+.txt) ###.*?END File: (\\w+/\\w+.txt) ###\",\n",
    "    r\"### BEGIN File: ([\\w./-]+\\.txt) ###.*?END File: ([\\w./-]+\\.txt) ###\",\n",
    "    r\"### BEGIN File: (\\w+/\\w+.pgerd) ###.*?END File: (\\w+/\\w+.pgerd) ###\",\n",
    "    r\"### BEGIN File: \\w+\\.lock ###.*?END File: \\w+\\.lock ###\",\n",
    "    r\"### BEGIN File: \\w+\\.yml ###.*?END File: \\w+\\.yml ###\",\n",
    "    r\"### BEGIN File: \\w+\\.yaml ###.*?END File: \\w+\\.yaml ###\",\n",
    "    r\"### BEGIN File: \\w+\\.toml ###.*?END File: \\w+\\.toml ###\",\n",
    "    r\"### BEGIN File: \\w+\\.log ###.*?END File: \\w+\\.log ###\",\n",
    "    #r\"### BEGIN File: model_schema\\/model_schema_design\\.pgerd ###.*?END File: model_schema\\/model_schema_design\\.pgerd ###\",\n",
    "    r\"### BEGIN File: package\\.json ###.*?END File: package\\.json ###\",\n",
    "    r\"### BEGIN File: setup\\.py ###.*?END File: setup\\.py ###\",\n",
    "    r\"### BEGIN File: tailwind.config\\.js ###.*?END File: tailwind.config\\.js ###\",\n",
    "    r\"### BEGIN File: tailwind.config\\.ts ###.*?END File: tailwind.config\\.ts ###\",\n",
    "    r\"### BEGIN File: Dockerfile ###.*?END File: Dockerfile ###\",\n",
    "    ]\n",
    "    cleaned_text = re.sub(\"|\".join(patterns), '', text, flags=re.DOTALL | re.MULTILINE)\n",
    "    return cleaned_text\n",
    "#textt = clean_packages(data['code_content'][151])\n",
    "week1_python['code_content'] = week1_python['code_content'].apply(clean_packages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_content(text):\n",
    "    pattern = r\"### BEGIN File: README\\.md ###.*?END File: README\\.md ###\"\n",
    "    cleaned_text = re.sub(pattern, '', text, flags=re.DOTALL)\n",
    "    return cleaned_text\n",
    "#data['code_content'][182] = clean_content(data['code_content'][182])\n",
    "# Assuming your DataFrame is named 'data' and the column containing the text is named 'code_content'\n",
    "week1_python['code_content'] = week1_python['code_content'].apply(clean_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_License(text):\n",
    "    pattern = r'BEGIN File: LICENSE.*?END File: LICENSE'\n",
    "    cleaned_text = re.sub(pattern, '', text, flags=re.DOTALL)\n",
    "    return cleaned_text\n",
    "# data['code_content'][182] = clean_License(data['code_content'][182])\n",
    "# Assuming your DataFrame is named 'data' and the column containing the text is named 'code_content'\n",
    "week1_python['code_content'] = week1_python['code_content'].apply(clean_License)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_comments(text):\n",
    "    pattern = r'#.*?\\n'\n",
    "    cleaned_text = re.sub(pattern, '', text, flags=re.DOTALL)\n",
    "    return cleaned_text\n",
    "# data['code_content'][182] = remove_comments(data['code_content'][182])\n",
    "# Assuming your DataFrame is named 'data' and the column containing the text is named 'code_content'\n",
    "week1_python['code_content'] = week1_python['code_content'].apply(remove_comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_perged_files(text):\n",
    "    pattern = r'### BEGIN File:.*?model_schema/model_schema_design\\.pgerd.*?### END File'\n",
    "    cleaned_text = re.sub(pattern, '', text, flags=re.DOTALL)\n",
    "    return cleaned_text\n",
    "# data['code_content'][182] = clean_perged_files(data['code_content'][182])\n",
    "# Assuming your DataFrame is named 'data' and the column containing the text is named 'code_content'\n",
    "week1_python['code_content'] = week1_python['code_content'].apply(clean_perged_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_content(text):\n",
    "    pattern = r'Content:\\s*(.*?)(?=\\s*Commit History:)'\n",
    "    matches = re.findall(pattern, text, flags=re.DOTALL)\n",
    "    if matches:\n",
    "        return '\\n'.join(matches)\n",
    "    else:\n",
    "        return text\n",
    "# data['code_content'][182] = extract_content(data['code_content'][182])\n",
    "# Assuming your DataFrame is named 'df' and the column containing the text is named 'text_column'\n",
    "week1_python['code_content'] = week1_python['code_content'].apply(extract_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def clean_installs(text):\n",
    "    pattern = r\"pip install \\w+\\n\"\n",
    "    cleaned_text = re.sub(pattern, '', text, flags=re.DOTALL)\n",
    "    return cleaned_text\n",
    "# data['code_content'][182] = clean_perged_files(data['code_content'][182])\n",
    "# Assuming your DataFrame is named 'data' and the column containing the text is named 'code_content'\n",
    "week1_python['code_content'] = week1_python['code_content'].apply(clean_installs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The column does not contain empty string values.\n"
     ]
    }
   ],
   "source": [
    "column_name = 'code_content'\n",
    "\n",
    "# Check if the column contains empty strings\n",
    "has_empty_values = any(week1_python[column_name] == '')\n",
    "\n",
    "if has_empty_values:\n",
    "    print(\"The column contains empty string values.\")\n",
    "else:\n",
    "    print(\"The column does not contain empty string values.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>code_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>from sqlalchemy import create_engine\\nimport p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>766</td>\n",
       "      <td>from sqlalchemy import create_engine\\n\\n\\nprin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>665</td>\n",
       "      <td>%reload_ext autoreload\\n\\n%autoreload 2\\nimpor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>606</td>\n",
       "      <td>import seaborn as sns\\nimport matplotlib.pyplo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>699</td>\n",
       "      <td>%\\n%\\n%import pandas as pd\\n\\nfrom sqlalchemy ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id                                       code_content\n",
       "0      619  from sqlalchemy import create_engine\\nimport p...\n",
       "1      766  from sqlalchemy import create_engine\\n\\n\\nprin...\n",
       "2      665  %reload_ext autoreload\\n\\n%autoreload 2\\nimpor...\n",
       "3      606  import seaborn as sns\\nimport matplotlib.pyplo...\n",
       "4      699  %\\n%\\n%import pandas as pd\\n\\nfrom sqlalchemy ..."
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "week1_python.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "week1_python.to_csv('./data_files/week1_python.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
